{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images: 1000\n",
      "total training dog images: 1000\n",
      "total validation cat images: 500\n",
      "total validation dog images: 500\n",
      "total test cat images: 500\n",
      "total test dog images: 500\n"
     ]
    }
   ],
   "source": [
    "# Create smaller dataset for Dogs vs. Cats\n",
    "import os, shutil\n",
    "\n",
    "original_dataset_dir = '/home/ec2-user/SageMaker/all/train'\n",
    "\n",
    "base_dir = '/home/ec2-user/SageMaker/data/transferLearning'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "# Create directories\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "if not os.path.exists(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "if not os.path.exists(validation_dir):\n",
    "    os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir,'cats')\n",
    "if not os.path.exists(train_cats_dir):\n",
    "    os.mkdir(train_cats_dir)\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir,'dogs')\n",
    "if not os.path.exists(train_dogs_dir):\n",
    "    os.mkdir(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir,'cats')\n",
    "if not os.path.exists(validation_cats_dir):\n",
    "    os.mkdir(validation_cats_dir)\n",
    "\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "if not os.path.exists(validation_dogs_dir):\n",
    "    os.mkdir(validation_dogs_dir)\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')     \n",
    "if not os.path.exists(test_cats_dir):\n",
    "    os.mkdir(test_cats_dir)\n",
    "\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "if not os.path.exists(test_dogs_dir):\n",
    "    os.mkdir(test_dogs_dir)\n",
    "\n",
    "# Copy first 1000 cat images to train_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(0, 1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 cat images to validation_cats_dir\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1001, 1501)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Copy next 500 cat images to test_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1502,2002)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy first 1000 dog images to train_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(0,1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "                                                \n",
    "# Copy next 500 dog images to validation_dogs_dir\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1001,1501)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)    \n",
    "\n",
    "\n",
    "# Copy next 500 dog images to test_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1502,2002)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "                                                \n",
    "# Sanity checks\n",
    "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
    "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_dir = '/home/ec2-user/SageMaker/data/transferLearning'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten it out first\n",
    "train_features = np.reshape(train_features, (2000, 4*4*512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4*4*512))\n",
    "test_features = np.reshape(test_features, (1000, 4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.6158 - acc: 0.6560 - val_loss: 0.4514 - val_acc: 0.8290\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 0.4225 - acc: 0.8150 - val_loss: 0.3716 - val_acc: 0.8600\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 0.3601 - acc: 0.8415 - val_loss: 0.3454 - val_acc: 0.8550\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 0.3103 - acc: 0.8705 - val_loss: 0.3026 - val_acc: 0.8880\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 0.2833 - acc: 0.8875 - val_loss: 0.2902 - val_acc: 0.8820\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.2621 - acc: 0.8965 - val_loss: 0.2742 - val_acc: 0.8960\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 0.2389 - acc: 0.9025 - val_loss: 0.2660 - val_acc: 0.8970\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 0.2395 - acc: 0.9040 - val_loss: 0.2604 - val_acc: 0.9020\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 0.2235 - acc: 0.9150 - val_loss: 0.2586 - val_acc: 0.8960\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.2073 - acc: 0.9215 - val_loss: 0.2511 - val_acc: 0.9020\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.1995 - acc: 0.9235 - val_loss: 0.2530 - val_acc: 0.8950\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.1834 - acc: 0.9390 - val_loss: 0.2457 - val_acc: 0.8990\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 0.1815 - acc: 0.9335 - val_loss: 0.2437 - val_acc: 0.9020\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.1679 - acc: 0.9370 - val_loss: 0.2443 - val_acc: 0.8970\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.1605 - acc: 0.9420 - val_loss: 0.2407 - val_acc: 0.9000\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.1528 - acc: 0.9490 - val_loss: 0.2488 - val_acc: 0.8930\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.1472 - acc: 0.9480 - val_loss: 0.2382 - val_acc: 0.9030\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.1407 - acc: 0.9495 - val_loss: 0.2374 - val_acc: 0.9050\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.1404 - acc: 0.9445 - val_loss: 0.2404 - val_acc: 0.8990\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.1283 - acc: 0.9555 - val_loss: 0.2377 - val_acc: 0.9030\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.1253 - acc: 0.9570 - val_loss: 0.2368 - val_acc: 0.9040\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.1226 - acc: 0.9605 - val_loss: 0.2547 - val_acc: 0.8900\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.1203 - acc: 0.9595 - val_loss: 0.2386 - val_acc: 0.9010\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.1126 - acc: 0.9605 - val_loss: 0.2399 - val_acc: 0.9000\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.1061 - acc: 0.9660 - val_loss: 0.2454 - val_acc: 0.8960\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.0995 - acc: 0.9680 - val_loss: 0.2418 - val_acc: 0.9000\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0953 - acc: 0.9680 - val_loss: 0.2400 - val_acc: 0.9040\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0968 - acc: 0.9685 - val_loss: 0.2495 - val_acc: 0.8980\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.0898 - acc: 0.9705 - val_loss: 0.2427 - val_acc: 0.9010\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.0835 - acc: 0.9775 - val_loss: 0.2527 - val_acc: 0.9020\n"
     ]
    }
   ],
   "source": [
    "# importing layers, models and optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "# construct model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim = 4*4*512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=2e-5),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['acc'])\n",
    "\n",
    "# Run the model\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                   epochs = 30,\n",
    "                   batch_size = 20,\n",
    "                   validation_data = (validation_features, validation_labels))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
