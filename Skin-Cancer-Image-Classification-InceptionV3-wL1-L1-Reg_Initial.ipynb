{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Classification -- What are we going to do today!\n",
    "\n",
    "\n",
    "The following article introduces this work done by Andre Esteva and his team, Dermatologist-level classification of skin cancer with deep neural networks.\n",
    "\n",
    "The versatility of the smartphone is starting to have a serious impact in the medical world, with the ability to reveal low red blood cell counts, sleep apnea and even HIV all very real possibilities. Skin cancer too is a condition that might feel the wrath of these modern diagnostic tools, with an iPhone app way back in 2011 offering risk assessments on suspect moles. But a new research project at Stanford University is promising to bring things up to a professional grade of diagnosis, through a deep learning algorithm that can detect potential cancers with the same accuracy as dermatologists in early tests.\n",
    "\n",
    "As is the case with all cancers, early detection of skin cancer is critical to survival rates. For melanoma detected in its early stages, the five-year survival rate is 97 percent, but those detected in its later stages carry a survival rate of just 14 percent. However, not everybody has ready access or the funds to drop by the doctor's office and get their skin oddities checked out as soon as they appear.\n",
    "\n",
    "#### Step 0: Getting the data\n",
    "\n",
    "A bit about data and pre-processing\n",
    "\n",
    "#### Step 1: Importing necessary modules\n",
    "\n",
    "#### Step 2: Loading a pre-trained module already \n",
    "\n",
    "Something about the pre-trained models such as InceptionV3, ResNets, GoogLeNet etc\n",
    "\n",
    "#### Step 3: Pre-processing the data\n",
    "\n",
    "#### Step 4: Building your model\n",
    "\n",
    "#### Step 5: Training your model\n",
    "\n",
    "#### Step 6: Doing some Transfer Learning\n",
    "\n",
    "#### Step 7: Prediction function and classifying images\n",
    "\n",
    "#### Addendum : Lot's of Rinse and Repeat in between  😀\n",
    "\n",
    "WQe do a lot of stuff such as playing around with the learning_rate, \n",
    "\n",
    "#### Addendum on Steroids : Homework Exercise\n",
    "\n",
    "1. Build an App with Android (using TensorFlow Lite) or iOS (Apple's coreML package)\n",
    "\n",
    "###### Useful Links:\n",
    "1. [Stanford article](https://news.stanford.edu/2017/01/25/artificial-intelligence-used-identify-skin-cancer/)\n",
    "2. [Other news - Startup Grind](https://medium.com/startup-grind/how-can-ai-detect-skin-cancer-with-your-smartphone-df65cf040d48)\n",
    "3. [Research paper](https://www.nature.com/articles/nature21056.epdf)\n",
    "\n",
    "Notes: [Waya.ai's link gone dead](https://blog.waya.ai/ground-up-hands-on-deep-learning-tutorial-diagnosing-skin-cancer-w-dermatologist-level-61a90fe9f269)\n",
    "\n",
    "4. More useful links as of Jan 2018 - see if still workds else modify the code to do so:\n",
    "[ISIC Archive downloader : ](https://github.com/GalAvineri/ISIC-Archive-Downloader)\n",
    "\n",
    "5. [Original contest was here: ](https://challenge.kitware.com/#phase/5840f53ccad3a51cc66c8dab)\n",
    "[Udacity's wrapper on the contest is here -->](https://github.com/udacity/dermatologist-ai)\n",
    "[Dasato](https://dasoto.github.io/skincancer/)\n",
    "\n",
    "6. More links for ideas: [VGG, scrape and more](https://github.com/tanmoyopenroot/cancer_nn) | [Skin-Lesion-Analysis](https://github.com/JiteshPshah/Skin-Lesion-Analysis-Towards-Melanoma-Detection) | [RECOD guys](https://github.com/learningtitans/isbi2017-part3), [train_image](https://github.com/learningtitans/isbi2017-part3/blob/master/train_image_classifier.py) | [Inception modules explained](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/) | [VGG transfer learning](https://github.com/swapnilpote/isic-2017) | Note to self : SqueezeNet , MobileNet\n",
    "\n",
    "\n",
    "**Before we start** [No need to do this on your own server though), [more information look here](https://www.tensorflow.org/programmers_guide/using_gpu)\n",
    "\n",
    "```python\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config, ...)\n",
    "```\n",
    "**GET THESE INTO your direcory called \"data\"\n",
    "```shell\n",
    "mkdir data\n",
    "wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/train.zip\n",
    "wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/test.zip\n",
    "wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/valid.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Import the necessary modules \n",
    "\n",
    "Go ahead and import the following:\n",
    "InceptionV3, preprocessing...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications import inception_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Load the pre-trained model \n",
    "\n",
    "More about the [pre-trained models](https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Signature: InceptionV3(include_top=True, weights='imagenet', input_tensor=None, \n",
    "input_shape=None, pooling=None, classes=1000)\n",
    "Docstring:\n",
    "Instantiates the Inception v3 architecture.\n",
    "\n",
    "Optionally loads weights pre-trained\n",
    "on ImageNet. Note that when using TensorFlow,\n",
    "for best performance you should set\n",
    "`image_data_format='channels_last'` in your Keras config\n",
    "at ~/.keras/keras.json.\n",
    "The model and the weights are compatible with both\n",
    "TensorFlow and Theano. The data format\n",
    "convention used by the model is the one\n",
    "specified in your Keras config file.\n",
    "Note that the default input image size for this model is 299x299.\n",
    "\n",
    "# Arguments\n",
    "    include_top: whether to include the fully-connected\n",
    "        layer at the top of the network.\n",
    "    weights: one of `None` (random initialization)\n",
    "        or 'imagenet' (pre-training on ImageNet).\n",
    "    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "        to use as image input for the model.\n",
    "    input_shape: optional shape tuple, only to be specified\n",
    "        if `include_top` is False (otherwise the input shape\n",
    "        has to be `(299, 299, 3)` (with `channels_last` data format)\n",
    "        or `(3, 299, 299)` (with `channels_first` data format).\n",
    "        It should have exactly 3 inputs channels,\n",
    "        and width and height should be no smaller than 139.\n",
    "        E.g. `(150, 150, 3)` would be one valid value.\n",
    "    pooling: Optional pooling mode for feature extraction\n",
    "        when `include_top` is `False`.\n",
    "        - `None` means that the output of the model will be\n",
    "            the 4D tensor output of the\n",
    "            last convolutional layer.\n",
    "        - `avg` means that global average pooling\n",
    "            will be applied to the output of the\n",
    "            last convolutional layer, and thus\n",
    "            the output of the model will be a 2D tensor.\n",
    "        - `max` means that global max pooling will\n",
    "            be applied.\n",
    "    classes: optional number of classes to classify images\n",
    "        into, only to be specified if `include_top` is True, and\n",
    "        if no `weights` argument is specified.\n",
    "\n",
    "# Returns\n",
    "    A Keras model instance.\n",
    "\"\"\"\n",
    "base_model = inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "print('loaded model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Pre-processing the data\n",
    "\n",
    "- Read more on Keras documentation [here](https://keras.io/preprocessing/image/)\n",
    "\n",
    "An example:\n",
    "```python\n",
    "keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=K.image_data_format())\n",
    "```    \n",
    "\n",
    "Example code:\n",
    "\n",
    "```python\n",
    "# we create two instances with the same arguments\n",
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90.,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d66e01afce4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmask_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata_gen_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# create two instances with the same arguments for train and test // basically you're merging stuff here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata_gen_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtest_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata_gen_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#Define the dictionary for Image data Generator\n",
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90.,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2)\n",
    "\n",
    "# add stuff here)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "# create two instances with the same arguments for train and test // basically you're merging stuff here\n",
    "train_datagen = image.ImageDataGenerator(**data_gen_args)\n",
    "test_datagen = image.ImageDataGenerator(**data_gen_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Loading the data\n",
    "\n",
    "Explanation: Use this function and this is what it does. You task is to ...\n",
    "Hint: Try doing ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\"data/skin-cancer/train\", \n",
    "                                                    target_size=(299,299), \n",
    "                                                    batch_size=100)\n",
    "\n",
    "valid_generator = test_datagen.flow_from_directory(\"data/skin-cancer/valid\", \n",
    "                                                   target_size=(299,299), \n",
    "                                                   batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Building your model\n",
    "\n",
    "\n",
    "#### Building your model architecture\n",
    "\n",
    "**BTW -- you should see something like this on the terminal**\n",
    "\n",
    "On your own dedicated box you don't need to throttle the GPU use but on a shared box )or shared activities with your own GPU operations, you can add the command we provided in the first cell of this notebook.\n",
    "\n",
    "```shell\n",
    "2018-02-15 11:21:51.550974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2018-02-15 11:21:51.551358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: \n",
    "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
    "pciBusID: 0000:01:00.0\n",
    "totalMemory: 7.93GiB freeMemory: 7.81GiB\n",
    "2018-02-15 11:21:51.551372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/deeplearn/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/deeplearn/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D,MaxPooling2D,Flatten\n",
    "\n",
    "# Your Model\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "# activation='relu', input_shape=(10000,))) model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "#                        activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_95 (Conv2D)           (None, 299, 299, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 150, 150, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 150, 150, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 75, 75, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               47317504  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 47,329,587\n",
      "Trainable params: 47,329,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/deeplearn/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early stopping\n",
    "\n",
    "### Try regularizing if when you unfreeze the model...\n",
    "\n",
    "**What it is?**\n",
    "\n",
    "In machine learning, early stopping is a form of regularization used to avoid overfitting when training a learner with an iterative method, such as gradient descent. Such methods update the learner so as to make it better fit the training data with each iteration. Up to a point, this improves the learner's performance on data outside of the training set. Past that point, however, improving the learner's fit to the training data comes at the expense of increased generalization error. Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit. Early stopping rules have been employed in many different machine learning methods, with varying amounts of theoretical foundation.\n",
    "More on [Wikipedia](https://en.wikipedia.org/wiki/Early_stopping)\n",
    "\n",
    "**How we do it in Keras**\n",
    "\n",
    "```python\n",
    "\n",
    "keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
    "Stop training when a monitored quantity has stopped improving.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "# Save the model with best weights, do create a model folder with mkdir saved_model\n",
    "checkpointer = ModelCheckpoint('saved_model/model.hdf5', verbose=1,save_best_only=True)\n",
    "# Stop the training if the model shows no improvement \n",
    "stopper = EarlyStopping(monitor='val_loss',\n",
    "                        min_delta=0.1,\n",
    "                        patience=0,\n",
    "                        verbose=1,\n",
    "                        mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Training your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "                                  steps_per_epoch = 20,\n",
    "                                  validation_data=valid_generator,\n",
    "                                  validation_steps=3, \n",
    "                                  epochs=60,\n",
    "                                  verbose=1,\n",
    "                                  callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6:  Transfer Learning\n",
    "\n",
    "**What is it?**\n",
    "\n",
    "Models out there\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Transfer learning is a machine learning method which utilizes a pre-trained neural network. For example, the image recognition model called Inception-v3 consists of two parts:\n",
    "\n",
    "- Feature extraction part with a convolutional neural network.\n",
    "- Classification part with fully-connected and softmax layers.\n",
    "\n",
    "The pre-trained Inception-v3 model achieves state-of-the-art accuracy for recognizing general objects with 1000 classes, like \"Zebra\", \"Dalmatian\", and \"Dishwasher\". The model extracts general features from input images in the first part and classifies them based on those features in the second part.\n",
    "\n",
    "<img src=\"https://codelabs.developers.google.com/codelabs/cpb102-txf-learning/img/bfea25ba557fbffc.png\">\n",
    "\n",
    "**Links**\n",
    "\n",
    "\n",
    "In transfer learning, when you build a new model to classify your original dataset, you reuse the feature extraction part and re-train the classification part with your dataset. Since you don't have to train the feature extraction part (which is the most complex part of the model), you can train the model with less computational resources and training time.\n",
    "\n",
    "[1](https://kwotsin.github.io/tech/2017/02/11/transfer-learning.html)\n",
    "[2 Goog Codelab](https://codelabs.developers.google.com/codelabs/cpb102-txf-learning/index.html?index=..%2F..%2Findex#1)\n",
    "\n",
    "Explain a bit about it...\n",
    "\n",
    "**Little tip:**\n",
    "\n",
    "Watch out for this error if you do\n",
    "```python\n",
    "model = Model(input=...)\n",
    "```\n",
    "it might throw this error:\n",
    "```shell\n",
    "UserWarning: Update your Model call to the Keras 2 API: Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, None, None, 32 864         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, None, None, 32 96          conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, None, None, 32 0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, None, None, 32 9216        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, None, None, 32 96          conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, None, None, 32 0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, None, None, 64 18432       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, None, None, 64 192         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, None, None, 64 0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, None, None, 64 0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, None, None, 80 5120        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, None, None, 80 240         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, None, None, 80 0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, None, None, 19 138240      activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, None, None, 19 576         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, None, None, 19 0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, None, None, 19 0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, None, None, 64 12288       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, None, None, 64 192         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, None, None, 64 0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, None, None, 48 9216        max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, None, None, 96 55296       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, None, None, 48 144         conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, None, None, 96 288         conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, None, None, 48 0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, None, None, 96 0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, None, None, 19 0           max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, None, None, 64 12288       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, None, None, 64 76800       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, None, None, 96 82944       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, None, None, 32 6144        average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, None, None, 64 192         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, None, None, 64 192         conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, None, None, 96 288         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, None, None, 32 96          conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, None, None, 64 0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, None, None, 64 0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, None, None, 96 0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, None, None, 32 0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, None, None, 25 0           activation_6[0][0]               \n",
      "                                                                   activation_8[0][0]               \n",
      "                                                                   activation_11[0][0]              \n",
      "                                                                   activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, None, None, 64 192         conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, None, None, 64 0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, None, None, 48 12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, None, None, 96 55296       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, None, None, 48 144         conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, None, None, 96 288         conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, None, None, 48 0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, None, None, 96 0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePool (None, None, None, 25 0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, None, None, 64 76800       activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, None, None, 96 82944       activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, None, None, 64 16384       average_pooling2d_2[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, None, None, 64 192         conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, None, None, 64 192         conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, None, None, 96 288         conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, None, None, 64 192         conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, None, None, 64 0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, None, None, 64 0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, None, None, 96 0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, None, None, 64 0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, None, None, 28 0           activation_13[0][0]              \n",
      "                                                                   activation_15[0][0]              \n",
      "                                                                   activation_18[0][0]              \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, None, None, 64 192         conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, None, None, 64 0           batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, None, None, 48 13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, None, None, 96 55296       activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, None, None, 48 144         conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, None, None, 96 288         conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, None, None, 48 0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, None, None, 96 0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePool (None, None, None, 28 0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, None, None, 64 76800       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, None, None, 96 82944       activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, None, None, 64 18432       average_pooling2d_3[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, None, None, 64 192         conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, None, None, 64 192         conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, None, None, 96 288         conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, None, None, 64 192         conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, None, None, 64 0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, None, None, 64 0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, None, None, 96 0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, None, None, 64 0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, None, None, 28 0           activation_20[0][0]              \n",
      "                                                                   activation_22[0][0]              \n",
      "                                                                   activation_25[0][0]              \n",
      "                                                                   activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, None, None, 64 18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, None, None, 64 192         conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, None, None, 64 0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, None, None, 96 55296       activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, None, None, 96 288         conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, None, None, 96 0           batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, None, None, 38 995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, None, None, 96 82944       activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, None, None, 38 1152        conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, None, None, 96 288         conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, None, None, 38 0           batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, None, None, 96 0           batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, None, None, 28 0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, None, None, 76 0           activation_27[0][0]              \n",
      "                                                                   activation_30[0][0]              \n",
      "                                                                   max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, None, None, 12 384         conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, None, None, 12 0           batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, None, None, 12 114688      activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, None, None, 12 384         conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, None, None, 12 0           batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, None, None, 12 114688      activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, None, None, 12 384         conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, None, None, 12 384         conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, None, None, 12 0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, None, None, 12 0           batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, None, None, 12 114688      activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, None, None, 12 114688      activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, None, None, 12 384         conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, None, None, 12 384         conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, None, None, 12 0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, None, None, 12 0           batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePool (None, None, None, 76 0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, None, None, 19 147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, None, None, 19 172032      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, None, None, 19 172032      activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_4[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, None, None, 19 576         conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, None, None, 19 576         conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, None, None, 19 576         conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNor (None, None, None, 19 576         conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, None, None, 19 0           batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, None, None, 19 0           batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, None, None, 19 0           batch_normalization_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, None, None, 19 0           batch_normalization_40[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, None, None, 76 0           activation_31[0][0]              \n",
      "                                                                   activation_34[0][0]              \n",
      "                                                                   activation_39[0][0]              \n",
      "                                                                   activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNor (None, None, None, 16 480         conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, None, None, 16 0           batch_normalization_45[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, None, None, 16 179200      activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNor (None, None, None, 16 480         conv2d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, None, None, 16 0           batch_normalization_46[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, None, None, 16 179200      activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNor (None, None, None, 16 480         conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNor (None, None, None, 16 480         conv2d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, None, None, 16 0           batch_normalization_42[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, None, None, 16 0           batch_normalization_47[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, None, None, 16 179200      activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, None, None, 16 179200      activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNor (None, None, None, 16 480         conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNor (None, None, None, 16 480         conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, None, None, 16 0           batch_normalization_43[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, None, None, 16 0           batch_normalization_48[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePool (None, None, None, 76 0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, None, None, 19 147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, None, None, 19 215040      activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, None, None, 19 215040      activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_5[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNor (None, None, None, 19 576         conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNor (None, None, None, 19 576         conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, None, None, 19 576         conv2d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNor (None, None, None, 19 576         conv2d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, None, None, 19 0           batch_normalization_41[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, None, None, 19 0           batch_normalization_44[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, None, None, 19 0           batch_normalization_49[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, None, None, 19 0           batch_normalization_50[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, None, None, 76 0           activation_41[0][0]              \n",
      "                                                                   activation_44[0][0]              \n",
      "                                                                   activation_49[0][0]              \n",
      "                                                                   activation_50[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNor (None, None, None, 16 480         conv2d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, None, None, 16 0           batch_normalization_55[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, None, None, 16 179200      activation_55[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNor (None, None, None, 16 480         conv2d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, None, None, 16 0           batch_normalization_56[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, None, None, 16 179200      activation_56[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNor (None, None, None, 16 480         conv2d_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNor (None, None, None, 16 480         conv2d_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, None, None, 16 0           batch_normalization_52[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_57 (Activation)       (None, None, None, 16 0           batch_normalization_57[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, None, None, 16 179200      activation_52[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, None, None, 16 179200      activation_57[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNor (None, None, None, 16 480         conv2d_53[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (None, None, None, 16 480         conv2d_58[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, None, None, 16 0           batch_normalization_53[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, None, None, 16 0           batch_normalization_58[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePool (None, None, None, 76 0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, None, None, 19 147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, None, None, 19 215040      activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, None, None, 19 215040      activation_58[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_6[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNor (None, None, None, 19 576         conv2d_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNor (None, None, None, 19 576         conv2d_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (None, None, None, 19 576         conv2d_59[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (None, None, None, 19 576         conv2d_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, None, None, 19 0           batch_normalization_51[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, None, None, 19 0           batch_normalization_54[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, None, None, 19 0           batch_normalization_59[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, None, None, 19 0           batch_normalization_60[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, None, None, 76 0           activation_51[0][0]              \n",
      "                                                                   activation_54[0][0]              \n",
      "                                                                   activation_59[0][0]              \n",
      "                                                                   activation_60[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)               (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNor (None, None, None, 19 576         conv2d_65[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, None, None, 19 0           batch_normalization_65[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)               (None, None, None, 19 258048      activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNor (None, None, None, 19 576         conv2d_66[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, None, None, 19 0           batch_normalization_66[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)               (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)               (None, None, None, 19 258048      activation_66[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNor (None, None, None, 19 576         conv2d_62[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNor (None, None, None, 19 576         conv2d_67[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, None, None, 19 0           batch_normalization_62[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, None, None, 19 0           batch_normalization_67[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)               (None, None, None, 19 258048      activation_62[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)               (None, None, None, 19 258048      activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNor (None, None, None, 19 576         conv2d_63[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNor (None, None, None, 19 576         conv2d_68[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, None, None, 19 0           batch_normalization_63[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, None, None, 19 0           batch_normalization_68[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePool (None, None, None, 76 0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)               (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)               (None, None, None, 19 258048      activation_63[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)               (None, None, None, 19 258048      activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_7[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNor (None, None, None, 19 576         conv2d_61[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNor (None, None, None, 19 576         conv2d_64[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNor (None, None, None, 19 576         conv2d_69[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNor (None, None, None, 19 576         conv2d_70[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, None, None, 19 0           batch_normalization_61[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, None, None, 19 0           batch_normalization_64[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, None, None, 19 0           batch_normalization_69[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, None, None, 19 0           batch_normalization_70[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, None, None, 76 0           activation_61[0][0]              \n",
      "                                                                   activation_64[0][0]              \n",
      "                                                                   activation_69[0][0]              \n",
      "                                                                   activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)               (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNor (None, None, None, 19 576         conv2d_73[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, None, None, 19 0           batch_normalization_73[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)               (None, None, None, 19 258048      activation_73[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNor (None, None, None, 19 576         conv2d_74[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, None, None, 19 0           batch_normalization_74[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)               (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, None, None, 19 258048      activation_74[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNor (None, None, None, 19 576         conv2d_71[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNor (None, None, None, 19 576         conv2d_75[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, None, None, 19 0           batch_normalization_71[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, None, None, 19 0           batch_normalization_75[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)               (None, None, None, 32 552960      activation_71[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, None, None, 19 331776      activation_75[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNor (None, None, None, 32 960         conv2d_72[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNor (None, None, None, 19 576         conv2d_76[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, None, None, 32 0           batch_normalization_72[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, None, None, 19 0           batch_normalization_76[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, None, None, 76 0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, None, None, 12 0           activation_72[0][0]              \n",
      "                                                                   activation_76[0][0]              \n",
      "                                                                   max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)               (None, None, None, 44 573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, None, None, 44 1344        conv2d_81[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_81 (Activation)       (None, None, None, 44 0           batch_normalization_81[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, None, None, 38 491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)               (None, None, None, 38 1548288     activation_81[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNor (None, None, None, 38 1152        conv2d_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, None, None, 38 1152        conv2d_82[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_78 (Activation)       (None, None, None, 38 0           batch_normalization_78[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, None, None, 38 0           batch_normalization_82[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)               (None, None, None, 38 442368      activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)               (None, None, None, 38 442368      activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)               (None, None, None, 38 442368      activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)               (None, None, None, 38 442368      activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePool (None, None, None, 12 0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, None, None, 32 409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNor (None, None, None, 38 1152        conv2d_79[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNor (None, None, None, 38 1152        conv2d_80[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNor (None, None, None, 38 1152        conv2d_83[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNor (None, None, None, 38 1152        conv2d_84[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)               (None, None, None, 19 245760      average_pooling2d_8[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNor (None, None, None, 32 960         conv2d_77[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_79 (Activation)       (None, None, None, 38 0           batch_normalization_79[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_80 (Activation)       (None, None, None, 38 0           batch_normalization_80[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, None, None, 38 0           batch_normalization_83[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_84 (Activation)       (None, None, None, 38 0           batch_normalization_84[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNor (None, None, None, 19 576         conv2d_85[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, None, None, 32 0           batch_normalization_77[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, None, None, 76 0           activation_79[0][0]              \n",
      "                                                                   activation_80[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, None, None, 76 0           activation_83[0][0]              \n",
      "                                                                   activation_84[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_85 (Activation)       (None, None, None, 19 0           batch_normalization_85[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, None, None, 20 0           activation_77[0][0]              \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_1[0][0]              \n",
      "                                                                   activation_85[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, None, None, 44 917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, None, None, 44 1344        conv2d_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, None, None, 44 0           batch_normalization_90[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, None, None, 38 786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, None, None, 38 1548288     activation_90[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, None, None, 38 1152        conv2d_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, None, None, 38 1152        conv2d_91[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, None, None, 38 0           batch_normalization_87[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, None, None, 38 0           batch_normalization_91[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, None, None, 38 442368      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, None, None, 38 442368      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, None, None, 38 442368      activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, None, None, 38 442368      activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePool (None, None, None, 20 0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, None, None, 32 655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, None, None, 38 1152        conv2d_88[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, None, None, 38 1152        conv2d_89[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, None, None, 38 1152        conv2d_92[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, None, None, 38 1152        conv2d_93[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)               (None, None, None, 19 393216      average_pooling2d_9[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNor (None, None, None, 32 960         conv2d_86[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, None, None, 38 0           batch_normalization_88[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, None, None, 38 0           batch_normalization_89[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, None, None, 38 0           batch_normalization_92[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, None, None, 38 0           batch_normalization_93[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, None, None, 19 576         conv2d_94[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, None, None, 32 0           batch_normalization_86[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, None, None, 76 0           activation_88[0][0]              \n",
      "                                                                   activation_89[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, None, None, 76 0           activation_92[0][0]              \n",
      "                                                                   activation_93[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, None, None, 19 0           batch_normalization_94[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, None, None, 20 0           activation_86[0][0]              \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_2[0][0]              \n",
      "                                                                   activation_94[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glob (None, 2048)          0           mixed10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 512)           1049088     global_average_pooling2d_2[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 512)           0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 3)             1539        dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 22,853,411\n",
      "Trainable params: 22,818,979\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the output layers for Inceptionv3\n",
    "# l2(0.001) means every coefficient in the weight matrix of the layer will add 0.001 * weight_coefficient_value to the total loss of the network. Note that because this penalty is only added at training time, the loss for this network will be much higher at training than at test time.\n",
    "\n",
    "last = base_model.output\n",
    "x = GlobalAveragePooling2D()(last)\n",
    "x = Dense(512, kernel_regularizer=regularizers.l1_l2(0.0001), activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(3,activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input,outputs=preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading weights for your model\n",
    "\n",
    "**A little bit about HDF5**\n",
    "\n",
    "HDF5 is a data model, library, and file format for storing and managing data. It supports an unlimited variety of datatypes, and is designed for flexible and efficient I/O and for high volume and complex data. HDF5 is portable and is extensible, allowing applications to evolve in their use of HDF5. The HDF5 Technology suite includes tools and applications for managing, manipulating, viewing, and analyzing data in the HDF5 format.\n",
    "\n",
    "[link:](https://support.hdfgroup.org/HDF5/) or [Wikipedia definition](https://en.wikipedia.org/wiki/Hierarchical_Data_Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the weights for the common layers from the benchmark model\n",
    "base_model.load_weights(filepath='yourpath/to/your/model.hdf5',by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze the original layers of Inception3\n",
    "\n",
    "A bit on finetuning trained models\n",
    "\n",
    "[An example on fine-tuning InceptionV3 in keras](https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html). Please look for latest work out there since this is from Oct 2016 and there might be latest stuff out there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "# Save the model with best weights\n",
    "checkpointer = ModelCheckpoint('saved_model/transfer_learning.hdf5', verbose=1,save_best_only=True)\n",
    "# Stop the traning if the model shows no improvement\n",
    "stopper = EarlyStopping(monitor='val_loss',min_delta=0.1,patience=1,verbose=1,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_transfer = model.fit_generator(train_generator, \n",
    "                                       steps_per_epoch = 20,\n",
    "                                       validation_data=valid_generator,\n",
    "                                       validation_steps=3, \n",
    "                                       epochs=100,\n",
    "                                       verbose=1,\n",
    "                                       callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Display the dictionary of training metrics values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(history_transfer.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, Plotting the graph for accuracy and loss \n",
    "\n",
    "But lets define a simple function first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff240d1f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkoSouCuKoiQh/w8zJtyvkHBCewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efef5f90a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training(history_transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we do some fine tuning \n",
    "\n",
    "- Unfreezing modules at the end and see what works?\n",
    "- Any other techniques?\n",
    "\n",
    "[Research more here] : Good homework for you guys and me! 😁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Can we come back and unfreeze layers at the tail? \n",
    "\n",
    "Unfreeze the last X number of layers in the model and train these as well?\n",
    "try only for inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does it help if we unfreeze some layers up front\n",
    "# reminder to self, come back if the accuracies don't improve\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Compile again\n",
    "\n",
    "What happens if we slow down the learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import #your optimizer\n",
    "\n",
    "# use with slow learning rate and momentum to standard value\n",
    "model.compile(optimizer=adam(lr=0.0001, beta_1=0.9, beta_2=0.999),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the mode wirth best validation loss\n",
    "\n",
    "checkpointer = ModelCheckpoint(\"saved_model/fine_tuning.hdf5\",\n",
    "                              verbose = 1,\n",
    "                              save_best_only = True,\n",
    "                              monitor = \"val_loss\")\n",
    "\n",
    "# Also we ensure that training stops if the validation loss doesn't improve\n",
    "\n",
    "stoptheshow = EarlyStopping(monitor = 'val_loss, val_acc',\n",
    "                           min_delta = 0.1,\n",
    "                           patience = 2,\n",
    "                           verbose = 1,\n",
    "                           mode = 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train this baby again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=20,\n",
    "                              validation_data = valid_generator,\n",
    "                              validation_steps = 3,\n",
    "                              epochs = 100,\n",
    "                              verbose = 1,\n",
    "                              callbacks = [checkpointer]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7:  Let's write our Prediction Function\n",
    "\n",
    "1. First load the model you just saved\n",
    "2. Then we write the prediction function\n",
    "3. Then we predict :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1 : load the trained model\n",
    "model.load_weights('saved_model/fine_tuning.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import cv2\n",
    "\n",
    "def predict_cancer(img_path):\n",
    "    # first we load img and set targt size of our input model\n",
    "    img = load_img(img_path, target_size = (299, 299))\n",
    "    x = img_to_array(img)                 # coverting image to array\n",
    "    x = np.expand_dims(x, axis=0)         # transform arrray to form a (1, x, y, z)\n",
    "    x = preprocess_input(x)               # use preprocess input function , subtract the mean of all images\n",
    "    p = np.argmax(model.predict(x))       # Store the argmax the predictions\n",
    "    \n",
    "    if p == 0:\n",
    "        print(\"melanoma\")\n",
    "    elif p == 1:\n",
    "        print(\"nevus\")\n",
    "    elif p == 2:\n",
    "        print(\"seborrheic_keratosis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cancer(\"data/test/melanoma/ISIC_0014181.jpg\")\n",
    "z = plt.imread(\"data/test/melanoma/ISIC_0014181.jpg\")\n",
    "plt.imshow(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cancer(\"data/test/nevus/ISIC_0012551.jpg\")\n",
    "z = plt.imread(\"data/test/nevus/ISIC_0012551.jpg\")\n",
    "plt.imshow(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXd4VGX2x7+HhFCVGpAakkAoAqKGpoigqKAgFlaIgKKr\ngorCgrqov7WsBRXFjshaUAEBsSEguhoEURAIIp0QILQkQBJ6TTLn98eZu/dmMi2TmUxm5nyeZ56Z\n29573jv3fu95z9uImaEoiqKEF5WCbYCiKIrif1TcFUVRwhAVd0VRlDBExV1RFCUMUXFXFEUJQ1Tc\nFUVRwhAV9zCGiKKI6AQRNffnvsGEiFoSkd/b7xJRHyLKtCxvI6IrvNnXh3N9QERP+Hq8onhDdLAN\nUEyI6IRlsTqAswCK7MsjmXlmadJj5iIANf29byTAzK39kQ4R3QNgGDP3sqR9jz/SVhR3qLhXIJj5\nf+Jq9wzvYeafXO1PRNHMXFgetimKJ/R+rFhoWCaEIKLniWgOEX1ORMcBDCOi7kS0koiOEFE2Eb1F\nRJXt+0cTERNRC/vyDPv274noOBGtIKL40u5r396PiNKJ6CgRvU1EvxHRCBd2e2PjSCLKIKLDRPSW\n5dgoInqdiPKIaCeAvm6uz5NENNth3btENNn++x4i2mLPzw67V+0qrX1E1Mv+uzoRfWa3bROASx32\n/T8i2mlPdxMR3Whf3wHAOwCusIe8ci3X9hnL8aPsec8jom+IqJE316Y019mwh4h+IqJ8Isohoscs\n5/mX/ZocI6I1RNTYWQiMiJYb/7P9ei6znycfwP8RUSsiWmI/R679utWyHB9nz+Mh+/Y3iaiq3ea2\nlv0aEdEpIqrnKr+KB5hZPxXwAyATQB+Hdc8DOAdgAOTFXA1AZwBdIaWwBADpAEbb948GwABa2Jdn\nAMgFkAygMoA5AGb4sG8DAMcBDLRvGwegAMAIF3nxxsZvAdQC0AJAvpF3AKMBbALQFEA9AMvktnV6\nngQAJwDUsKR9EECyfXmAfR8CcBWA0wA62rf1AZBpSWsfgF72368C+AVAHQBxADY77HsbgEb2/+R2\nuw0N7dvuAfCLg50zADxj/32t3cZOAKoCmAIg1ZtrU8rrXAvAAQBjAFQBcD6ALvZtjwP4C0Arex46\nAagLoKXjtQaw3Pif7XkrBHA/gCjI/ZgE4GoAMfb75DcAr1rys9F+PWvY97/cvm0agBcs5xkP4Otg\nP4eh/Am6Afpx8ce4FvdUD8c9AuAL+29ngj3Vsu+NADb6sO/dAH61bCMA2XAh7l7a2M2y/SsAj9h/\nL4OEp4xt1zsKjkPaKwHcbv/dD8A2N/suAPCg/bc7cd9j/S8APGDd10m6GwHcYP/tSdw/AfCiZdv5\nkHqWpp6uTSmv83AAq13st8Ow12G9N+K+04MNg4zzArgCQA6AKCf7XQ5gFwCyL68DcIu/n6tI+mhY\nJvTYa10gojZEtNBezD4G4N8A6rs5Psfy+xTcV6K62rex1Q6Wp3Gfq0S8tNGrcwHY7cZeAJgFIMX+\n+3b7smFHfyL6wx4yOALxmt1dK4NG7mwgohFE9Jc9tHAEQBsv0wUkf/9Lj5mPATgMoIllH6/+Mw/X\nuRlExJ3hbpsnHO/HC4hoLhHtt9sw3cGGTJbK+2Iw82+QUkAPImoPoDmAhT7apEBj7qGIYzPA9yGe\nYktmPh/AUxBPOpBkQzxLAAAREYqLkSNlsTEbIgoGnppqzgXQh4iaQMJGs+w2VgMwD8BESMikNoAf\nvbQjx5UNRJQA4D1IaKKePd2tlnQ9NdvMgoR6jPTOg4R/9nthlyPurvNeAIkujnO17aTdpuqWdRc4\n7OOYv5chrbw62G0Y4WBDHBFFubDjUwDDIKWMucx81sV+iheouIc+5wE4CuCkvUJqZDmccwGAS4ho\nABFFQ+K4sQGycS6AsUTUxF659k93OzNzDiR0MB0Sktlu31QFEgc+BKCIiPpDYsPe2vAEEdUm6Qcw\n2rKtJkTgDkHec/dCPHeDAwCaWis2HfgcwN+JqCMRVYG8fH5lZpclITe4u87zATQnotFEVIWIziei\nLvZtHwB4nogSSehERHUhL7UcSMV9FBHdB8uLyI0NJwEcJaJmkNCQwQoAeQBeJKmkrkZEl1u2fwYJ\n49wOEXqlDKi4hz7jAdwJqeB8H1LxGVCY+QCAwQAmQx7WRAB/Qjw2f9v4HoCfAWwAsBrifXtiFiSG\n/r+QDDMfAfAPAF9DKiUHQV5S3vA0pASRCeB7WISHmdcDeBvAKvs+rQH8YTn2vwC2AzhARNbwinH8\nYkj45Gv78c0BDPXSLkdcXmdmPgrgGgC3Ql446QCutG+eBOAbyHU+BqncrGoPt90L4AlI5XpLh7w5\n42kAXSAvmfkAvrTYUAigP4C2EC9+D+R/MLZnQv7ns8z8eynzrjhgVF4ois/Yi9lZAAYx86/BtkcJ\nXYjoU0gl7TPBtiXU0U5Mik8QUV9Iy5TTkKZ0BRDvVVF8wl5/MRBAh2DbEg5oWEbxlR4AdkJizdcB\nuFkrwBRfIaKJkLb2LzLznmDbEw5oWEZRFCUMUc9dURQlDAlazL1+/frcokWLYJ1eURQlJElLS8tl\nZndNjwEEUdxbtGiBNWvWBOv0iqIoIQkReeqlDUDDMoqiKGGJiruiKEoYouKuKIoShngUdyL6iIgO\nEtFGF9vJPlh/BhGtJ6JL/G+moiiKUhq88dynw83sN5Axs1vZP/dBxgJRFEVRgohHcWfmZZCBllwx\nEMCnLKwEUJvs04QpiqIowcEfMfcmKD5g/z64GNubiO6zz8+45tChQ344taIoiuKMcm3nzszTIMOJ\nIjk5Wcc9UBSlwsMM7NoFHDwIdOkCVLK4xDt3AnPnAlWqAHXrAvXqAfHxQEICUK1a8GwG/CPu+1F8\nlpqm8G0WGUWp8KxaBcyaBQwbBiQnB9uaikNWFvDRR0DlysDIkUDt2sG2CDh5EnjzTeDsWaBvX6Bz\nZyDaC8U7eBBYvVr+61Wr5HdenmxLTATuvx+48krgnXeAGTOAohKTBgrNmgH33guMHw9Ur+58n0Di\n1cBhRNQCwAJmbu9k2w2QmWmuh8y8/hYzd3Hcz5Hk5GTWHqpKKLF2LXDVVcDRo7Lctas86P37i8cW\nKM6dA378EZg9G9i7VzzEunWBqCjg8GEgP188xz59RMQaNADmzZOX0J9/Ah07isd52WXAwIFATIyZ\n9pkzQGoq0Lw50LatpHnokBz/3XdAXJykedVVwHnnFT9u505g2zax66uvgMJC2VarFvDww8DYsWKn\nlbw8YMcOsccVzEBODhAb61qMbTbgp5/k2hjXo1kzoEYN2b54sfw3mZniadts8sLp2VP+N0PoDQHf\nsUOuY36+vBQAOa5dO3P/6tWBadOA5ctle9Wq8iIbPx6oWVOOPXRIvPyMDGDlSmDRIqBJE+DFF4Eh\nQ4pfe18hojRm9uxaeJpBGzINWDZkvO59AP4OYBSAUfbtBOBdyAS7GwAkezMz96WXXsqKEmxsNuai\nIs/7bdrEXK8ec/PmzBs2ML/5JnNSEjPATMTcpQvz008zZ2a6TqOggHnJEuYXX2S+6SbmxETme+9l\nzs4298nIYH7wQebrr5dP377MdevKeerWZb7iCuYOHZibNGFu2JC5XTvmHj2Y27aVfayftm2ZR46U\n7dWqybrmzZmnTGHOz2d+/XXmRo3M/WvUYL74YuaoKFlu2ZK5Zk35HR0t+a9XT+wgMo+rU4d5/Hix\nPS2N+eabZX2jRsyrVpl5S09njo+XbZMmlbw+W7YwP/WUnNc4Z2KiXIfPPmM+c8bcr2fPkvkFmC+4\ngLlTJ/ndpg3z0qXMeXnMc+Yw3303c+vWJY9JTGQeMIB5xAjmceOYX3uNedky5uPHnf+P69Yxv/tu\n8f/NFcuWMScny3mqVGHu1o35oYeYU1M9H+sKAGvYC40N2pC/6rkrrrDZgBUrxPNMTwdeeQW4+GL/\nniMrC3j/ffHEioqA224Dbr8d6N4dIPt0zidOiEe3bZt4oczAr78CLVuadq5eDfzwg3iKf9gnoBsw\nQIrjF9inkj52DPjmG2DOHODAAVnXqhWQlCTHVqkCPPKIeHwzZ4pH2b69aUdSEpCSAlx7rXvPb88e\nSS8rC7jpJvHYjTQKC4H//hd47jm5tkSSn169gHHjpDSyahWwcaN4qikpQIcOQEEB8Pvv4iUfOWKe\nq0EDuQ4tW8p+jvHltWuBW28VD/zTTyUG3a+fnLNrV2DhQsnzyy9L+s89J6UTIiklXH+9eMIZGXKN\nd+4UT/7aa4EvvhAv+uWX5b7Izwdyc4Hdu+X/2rUL6N0beOwxubaOHDkCrFkj16Rz58CWugC5TxYu\nBJYtk2uclgY8+ijw9NO+pec3zz1QH/XcFSs2G/NffzH/85/McXHi6VStyly/PnP16sxff+35+L17\nmb//Xjw1V+TnM991l3iFROIV/u1vci6AuVIl8VwN79X4NGjAvHGjext272Z+4gnm2NiS3mGVKsy3\n3sr8xRfF7UtPNz3datXEc8zK8vqylRqbjfmnn5gffli8ykBy4ADz5ZebeYuLY962jbmwUEonAHNC\ngnzHxjJPnMi8f3/JdIqKmH/8kfnGG+V/SUlhzskJrO2BpLCQ+cQJ34+Heu5KRaGoSDyX996T36++\nKl6lsW36dOD114FNmyTme+214kUPHCjxz4EDxXt78UXxxhxbKzz+uHjU2dmyrk4d4KmngAceKO7p\npqYCd94p3uTo0fJJTJRtx48D334LbN1q7l+zpmxv2RJo3dr7SrGzZ8VLO3NGlqOjJd5dq5brY7Zu\nFQ8y1uNArqHF2bNynTdvFo+7cWNZzyz/5/Tp8j+NHOnd9bXZiv//kYi3nruKuxIwzp0Dpk4FJk+W\nInOTJrIuP1+K5D17AhMmABs2SMuTu+8GBg0qKXCnTwN33SVhjc6dJb3LLxdhePhhedhvvFEq6RIT\ngTfekBBEy5bAFVdIGkePSqVfUpKEPrSlixKqaFhG8Qtz5kglWI8ezM8/z/z778wzZjAPGyaVepdd\nxvz221IEN7DZmL/6yqwYu+IK5nnzpEIxL08qtoxwRXw889y5cow7bDbmTz6RcwJSkQgw9+ol4RDH\nfRctkkrOZs3k07w58+jRZSsOK0pFABqWUcrC0aNSnJ4xA+jUScIlaWnm9vr1peJryxbxvKOigIYN\nZVtBgTQJa9dOQjB9+5oVewbLl0vl15Ahziu9XHHqlHju778PjBkjlYGRXkxXIgsNyyil5swZiV3/\n8IO0Xc7JAf71L+DJJyVufPCgbG/RQlopGKK6caP00jNi3oCESO66y7tOI4qieI+34q6PXgRhs0nT\nsnXr5DsjQzp55OaaHTDOnZNKyJ49pSNLt27m8Q0aSPM2R9q3l4+iKBUHFfcwp7BQKhBnzpQWJ9a2\nyo0bixeekCAVjA0aSAVkr15mTz9FUUITFfcwg1lal+TnS8eaiROluWDr1sDgwRIuueQS6USjAq4o\n4YuKe5iwb5/0olywQNoWG3TuLE0D+/cvWampKEr4ouIe4hQVAVOmSKVnYaF0e2/aVAZSSkqS2LmK\nuqJEHiruFRRm8cT/+19ztLrERBnzIyVFRP3zzyWWvmOH9Op87z2JnyuKomhTyCBw4IA0MXzgAWlD\n7ozUVODqq2UApFatpOv6qlXSrd34y4xBlkaOlJ6d6qErSvijTSErKNnZIshbt0p3+GXLpLOPIy++\nKKMKLlok40Yb7NsnTRSjokTQG+lstYqiOEH79pUj+/bJDC579wKffCKz1vTpI2EVK6tWAT//LJMA\nWIUdkHj62LHAQw+psCuK4hoV93IiL0/aj+fkyLjVd9xhziRz9dXFBX7iRBnZcOTIoJmrKEqIo+Je\nTrz2mrQ3X7xYhn8FgAsvFKE/elS680+fLsPefvONjHZondZMURSlNGiFajmQny9zUfbvLy1cHNm9\nW8YZX7pUBuQ6fVrWBXqGGEVRQg9vK1TVcy8H3nhDpmz7v/9zvj0uTmLsr7wiXvxDD6mwK4pSNtRz\nDzBHjoh4G3M/euLwYWn2qMPYKoriDG0KWUF46y2ZINmV1+5InTqBtUdRlMhA/cMAcuyYzA16003A\nRRcF2xpFUSIJFfcA8uabEpbx1mtXFEXxFyruAeLwYWn+OHAgcOmlwbZGUZRIQ8U9QLz+urR8efbZ\nYFuiKEokouIeAPLypPnjoEEaa1cUJTiouAeAV1+Vdu3PPBNsSxRFiVRU3P3MwYPA228DQ4bI8AKK\noijBQMXdjzADo0fLNHdPPRVsaxRFiWS0E5Mf+eQT6YU6cSLQpk2wrVEUJZJRz91PZGSI196rF/Do\no8G2RlGUSEfF3Q+cOQMMHQrExACffiqzJCmKogQTDcv4yMKF0gN1+3Zgzx7AZpOQTLNmwbZMURRF\nxb3UMAOTJgETJgAJCTLxxh13AN26Af36Bds6RVEUwStxJ6K+AN4EEAXgA2Z+yWF7HQAfAUgEcAbA\n3cy80c+2Bp1z54BRo4CPPwZuu01mTqpWLdhWKYqilMRjzJ2IogC8C6AfgHYAUoioncNuTwBYx8wd\nAdwBeRGEHWPGiLA//TQwe7YKu6IoFRdvKlS7AMhg5p3MfA7AbAADHfZpByAVAJh5K4AWRNTQr5YG\nmd27gQ8+AO6/X3qeEgXbIkVRFNd4I+5NAOy1LO+zr7PyF4BbAICIugCIA9DUMSEiuo+I1hDRmkOH\nDvlmcZB4+WUR9McfD7YliqIonvFXU8iXANQmonUAHgLwJ4Aix52YeRozJzNzcmxsrJ9OHXj27QM+\n/BC4+25tDaMoSmjgTYXqfgBWSWtqX/c/mPkYgLsAgIgIwC4AO/1kY9B55RVp6qheu6IooYI3nvtq\nAK2IKJ6IYgAMATDfugMR1bZvA4B7ACyzC37Ik50NTJsGjBghE10riqKEAh49d2YuJKLRAH6ANIX8\niJk3EdEo+/apANoC+ISIGMAmAH8PoM3lyqRJQGGheu2KooQWXrVzZ+ZFABY5rJtq+b0CQJJ/TQs+\nubnA++/L0AIJCcG2RlEUxXt0bBk3vPUWcPq09EZVFEUJJVTcXXDsmEy6cfPNQNu2wbZGURSldKi4\nu2DqVODIEY21K4oSmqi4O+H0aWDyZOCaa4Dk5GBboyiKUnpU3J3w8cfAgQPAE08E2xJFURTfUHF3\nwpQpQJcuwJVXBtsSRVEU31Bxd2DjRmDTJhmjXQcHUxQlVFFxd2DOHKBSJWDQoGBboiiK4jsq7haY\nRdx79QIahtWAxYqiRBoq7hbWrZM5UQcPDrYliqIoZUPF3cKcOUBUFHDLLcG2RFEUpWyouNsxQjLX\nXAPUrx9saxRFUcqGirudVauAzEwNySiKEh6ouNuZMweIiQFuuinYliiKopQdFXcAx48Dn30G9OsH\n1K4dbGsURVHKjoo7ZByZ3FzgySeDbYmiKIp/iHhxP3QIePVVaSHTuXOwrVEURfEPES/uEycCp04B\nzz8fbEsURVH8R0SL+969MkjYnXfqhByKooQXES3uzz4r7dufeSbYliiKoviXiBX3vDxpIXPvvUDz\n5sG2RlEUxb9ErLh//jlw7hxw333BtkRRFMX/RKy4T58OXHwx0LFjsC1RFEXxPxEp7hs2AGlpwIgR\nwbZEURQlMESkuE+fDlSuDNx+e7AtURRFCQwRJ+4FBcCMGcCAATr6o6Io4UvEifvixcDBgxqSURQl\nvIk4cZ8+HWjQAOjbN9iWKIqiBI6IEvfDh4HvvgOGDpWYu6IoSrgSUeL+5ZcScx86NNiWKIqiBJaI\nEvdZs4BWrYBLLgm2JYqiKIElYsQ9Kwv45RcgJQUgCrY1iqIogSVixH3uXBkkLCUl2JYoiqIEnogR\n988/l+EG2rQJtiWKoiiBxytxJ6K+RLSNiDKIaIKT7bWI6Dsi+ouINhHRXf431Xd27ABWrYoAr/3E\nCSAnJ9hWKIpSAfAo7kQUBeBdAP0AtAOQQkTtHHZ7EMBmZr4IQC8ArxFRjJ9t9ZnZs+V78ODg2hFw\nxo0DevcOthWKolQAvPHcuwDIYOadzHwOwGwAAx32YQDnEREBqAkgH0ChXy0tA59/DvToEQHjti9f\nDqSnS3tPRVEiGm/EvQmAvZblffZ1Vt4B0BZAFoANAMYws80xISK6j4jWENGaQ4cO+Why6dizB9i0\nCRg0qFxOFzxOnAC2bgVsNmkapChKROOvCtXrAKwD0BhAJwDvENH5jjsx8zRmTmbm5NjYWD+d2j0r\nVsh3jx7lcrrgsW6dNAcCgN27g2uLlSlTgJdfDrYVZWPRIvEO1qwJtiWK4jXeiPt+AM0sy03t66zc\nBeArFjIA7AJQIdqlrFgBVKsWAZNyrF1r/t6zJ3h2ODJ9ukxSe+xYsC1xTlGR+VJ0xWuvSffmzp2B\n4cNlZnVFqeB4I+6rAbQionh7JekQAPMd9tkD4GoAIKKGAFoD2OlPQ31lxQp5JsN+LJm0NKBuXfld\nkTz3nBzgzBng66+DbYlz+vcHhgxxvf3oUWDZMuD++4EJE4AvvgAuvLD4y1RRKiAexZ2ZCwGMBvAD\ngC0A5jLzJiIaRUSj7Ls9B+AyItoA4GcA/2Tm3EAZ7S2nT8sz2L17sC0pB9LSJKOxsf7x3JcuBY4f\nL1sazGbTzBkzXO935Ajwxx9lO5cvrF4tY0AvXCgT6jrjhx+AwkKZ2WXiRGDzZqBOHeD664Fdu8z9\njh8HlixxnY6ilDNexdyZeREzJzFzIjO/YF83lZmn2n9nMfO1zNyBmdszs5snufxIS5PnMuzF/eRJ\nYMsWGTQnLq7snvvy5UCvXjIQz3/+I6ELXzh8WFru1K8PpKYC2dnO97vjDqkUycvz2WSfmDxZvk+e\nFKF3xoIFUiLq1k2WExLkhXDuHHDddcCBA8AHH8i1uuoq8eq//tpzqEdRAkxY91A1KlPDXtz/+kta\nyVx6qbT3LKvnPn++xLESE4H77gM6dQL27St9OobX/uCDYp/R4cDKwoUyDnNhoYimvygqAv79b4mR\nDx8uL5DUVHP7nj0SYrnL3t9uyRLnaSxaJF56dLS5vm1bsXnvXqBFC+Dee0X0p02T63bLLSL0J074\nLz9lJTsbePxxCZGFEn/+Kf03tAVY6WHmoHwuvfRSDjQ338ycmBjw0wSft99mBpj37mUeO5a5enVm\nm8339Nq0Ye7TR9KYPVvSfuWV0qfz889ybGoqc3Iy8yWXFN9++rT8Qa1bMzdsyDx4sO82W7HZmO+/\nX87dogVzQgJz3brMVasy//ab7PPII8xRUcy7dzNfdBHzVVeVTOe33ySN2bOdn+fbb5m7d2eeO9e8\n3gUFzC+/LMfNm+ef/PiDxx4Tm6ZNC7Yl3rFvH/OIEcxEYnfHjsxHjgTbqgoBgDXshcaGrbjbbMwX\nXMA8bFhAT1MxGDGCuUEDyfTrr8vfmpvrW1rbt8vxb7xhrqtdm/mBB0qf1syZktbmzaZdmzeb259/\nXtb9+CPz3Xcz16rFfO6cb3ZbMdL95z/NdQcPMrdqJSK/ahXz+eczp6TItrFjRfhPny6ezuOPywvg\n8OHSnf/YMTn/iy+WLR+OPPMM8z33lP64oiLmpk3FprZtZTnQPPOM53tm/nzmK66QF6KVrVuZa9Rg\njomRl/AXXzBHR8sL+MyZkukcP858+eWuX8IGo0czx8aan8GDmc+eLV2+KgARL+67dknu3n03oKep\nGHTowNyvn/z+8kvJ+Nq15vaCAuZDh7xL64035PiMDHPdxReb6Vs5eLDkg2nltdckrfx85uxs5kqV\n5IFfu5Z5yRLmatWYb71V9v3qK9l3yRLzeJuNOSvLO7sNPv5Y0hk2rKSI7dghJYTKlWWf1atl/fz5\nJc/NLNe1V6/Snd+gUSN56TqSk+N7qerSS8XO774rvv7sWUnXFUuWyHH9+8v3okW+nd9bDh5krlKF\nuX591/vYbMzt25e815iZp06V9Wlp5rpPP5V1KSkl/9cJE2Rbq1buX1wNG8o5779f7g+AefjwspVy\ng0DEi/usWSU1Liw5dUq8yyeflOU1ayTjX39t7vP668w1a3on8H36iHdn5eabS66z2aS00KePa+/n\n0UflITcenr59xTbjU60ac2ambDt2TDy18ePN4994Q/K2bZtnu5nFw65c2b1NaWlyLXr2NNcdOSIv\nnqeeMtdlZoqNr77q3bkdufJK5ssuK77uwAHJ43PP+ZbmBReITQkJZinj9Gk5V3Q088MPOy+x3XOP\n5PnwYeYmTeT6BJJnnzX/46NHne/z44/mPj/9VHzbhAnyPxYWFl8/caLsb71Htm6VfVu1km3z5zs/\nX16ebJ80yVz33HOybsKE0ucxiES8uD/0kJTs3DmWYcGKFfI3fmXvQ3bwoCy/+aa5zw03yLopU9yn\ndfSoPCiPPlp8/bhxIsRWD2ffPvPhHDrUucc0fDhzXJy5nJPD/M035sfRY7v2Wom/M4vHft55XKp4\n/9Klsv/337vfb/dueditJCdLiMDgnXckLW9fLI7ce29Jz3XxYkmzalUpWpaGc+ck/tyzp6Tx73/L\nNf/b32R5wAB5QdWuLXUwxn91+rSEu4YPl+WXXpL9163zLV+eOH1aXvrnn+/eu7ruOnlAAeb//Kf4\ntsGDnVeW2WzMDz4ox7z+uixfe63kb98+5ubN5UXnjOXL5biFC4unN3Kk6yJ+Tg7zggVeZbtUvPwy\n87JlPh8e8eKenOx7iTqkePdd+Rt375Zlm02EeNw4c7lePdnn8svdpzVvnuy3dGnx9UaFbXa2uS41\nVdZdf718P/ZYyfSuuYa5a1fv8/LWW5JWeroUm2Ni5IG1etnuMAR53z7vz2nw6KPyYjt5UgS9Xj2p\naPWVV18VW6wvkUmTzBLLTTeVLr09e+TY998XQa9aVQTbWrrYsEGuudVDNcJ0ixfLcn6+iOqdd/qe\nN3d88IGcb/Jk+f7ii5L7bNgg2559tnip06BLF+arr3aefmEh8y23yIvu3nuLOzLGNV+zpuRx06bJ\ntp07S6bXu7eUihz55z/lmD17POfbWw4flpfw00/7nEREi/vJk1JKffzxgJ2i4nD33eIhWr3q1q2Z\nBw2S39uukRGTAAAfb0lEQVS2yd/cpo3zm9vKiBHMdeqULO58950cu2KFuc6Ii2ZmShwdkHi3lQ4d\nmAcO9D4vO3dKOoMGyfeTT8onKqq4SObmSmlh//7ix993n1SY+hJD/f57OednnzHHx0uF2/btpU/H\nwIjjr1xprhs+nLlxYzO84KmEYWXlSjlmwQIRm+rVZXns2OL5LSpivu022TZzpghhw4bF/9OHHpIX\nmWN9xsmTcg+kp5c8/6OPing6q9A0sNmY27Vj7tRJSoGA5NWRv/9dXnC5udKa6fbbi29v0MB9xfGp\nU8w9ekj67dubeTtyREp7Q4eWPOYf/5BzOithGi9dx9KcUUfx3nuubSkt334raf7yi89JRLS4f/01\n/68RRthz4YUlKzuvuYa5c2f5PX06/68SDZCWJM4oKhJBc3zQmJk3bpRjZ80y140bJ95jUZF4P61b\nS/jHSmysFHtLmx+AuVkz5hMnzLCT9dxPPSXr3n67+LHduvleXDt+XDyCqCgRzlWrfEvHYOtWsfHT\nT811F10k9Q5nzjAnJUmc2J1YWjE88D//lOVZsyRW7EyszpyR61C5snzGjCm+3XjhO9YnGK2brHUP\nzNLE1gjBxcdL088zZ6Rew/pZuNB8QTLL/+8o0jk5Ug9z//2y3KuXNCc1OHFC0njhBffXIy9PXkTW\nSldmEfHoaLHZynXXScMAZyxYIOdcvrz4+oQEWe94X5cFo2WWt/+7E7wV97DsxPTll9JDvFevYFti\nYetWoEED6XDkL44ele7wjr204uLMjky//w7UqiW9Ka+4QoYBYC6Z1po1wKFDwA03lNzWooV8W7vb\np6dLr8xKlYCoKBmZLT3d3F5QAOTmAhdcULo89e8v35MnAzVqyMBAsbHSUxSQMSWmTJHfRi81QDpJ\nbdgAdOhQuvMZ1KwJdOkiv+fNk/OWhfh4uS7GNSkokF7EHTsCVaoAb70FbN8OfPihd+ntt4/V18Q+\n2nZKigyHUMnJI1ylivSSbdNGzjt0aPHtSUmSv5kzi683hoiwXlfr8qRJcp1uuw2oWlXOY/3ccAPQ\nuLFsB6QT3I4dxdP6+GPg7Flg7FjzOmVmmtuN38Y954q6dSWtSy4pvv7hh+VeeP/94uu3bAHaOc4x\nZMdYv3mzue70abnfY2KAn38GTp1ybw8gz3jDhu5HD01NBS6/XK5XgAk7cT93TjoPDhxYwQYL+/BD\nEc9Fi/yX5h9/iFA7invz5tIt/swZeTC7dRMRGDZMbsA//yyZ1vLl8u1sJqcaNURgrQ9herqIhEFS\nErBzpzlRyKFDYltpxf2RR2R2lVtvleWoKBGN77+XXqwzZshLIy6uuAhlZsowAmUZ/vPDD2WQsH79\nfE/DICZGhGvbNllOT5eb03j5XHedXDNn90NmJpCfX3zd/v1yQ9er5935a9cGfvoJ+PZbIDm55PZh\nw+Q+MATt4EHgxx/lHH/8IQJpsGKFiPnDD8sxs2YBL7zg/DNvnuQdAFq2LCnuv/0mQzQY9058vPSe\nPX3azLux3hdatAAuu0zGBDI4cUKcnbZtnR8TFydDx27ZYq7btk3u3zvukOfI2rvZZpPnyJFXX5Xr\n6Ky3MyD37fr15TZbWtiJ+88/i0NraEOFoKhIBAsQT9pfrFgBEJkep0FcnHxv2gRs3GiK/6BB8vA6\nemxGWi1aAI0aOT9XfLzpuRcUiJA7intRkbmPMfRAacW9fn0ZpZHIXNe/v4xT89tvwOuvy0znDz0k\n5zpwQPZZv16+yyLubdqIMPiLpCTTc9+wQb6t9vXuLS+TQsukZTabeHaPPFI8rf37xSt25qm7okED\n4MYbi19Lg8GD5cVp3Atz58r/949/yPDMVi92xQp5QcTEyDEpKcATTzj/WB2NxEQZouHsWXNdWpoM\nk2FgeOhGSdO4f3wVd0Cua1qaCAFgCrErz71SJfnvrXk2hH7UKCmtGCVHAHj+eXlRfPONue7AAbPk\nY9yLjixdatpXDoSduH/5JXDeecA11wTbEgtLl8rD2bAhsHKl87CIwX/+Y3p7nvj9d6B9e+B8h3lR\njPkE580r7tnXrSvjpMyaVXIwsBUr3A/CYy0+Z2aKIDmKO2CKma/i7oxrrpGX0vjx8tCNH2/aanjv\n69eLiF14YdnP5y+SkiT0YrOJfdHRIiIGvXvLaJLW4YNXr5ZxVIyXgcH+/WZIxh80bAj06SP3gs0m\nwnTRRcA998h247qePev70KqJiXL/GYKdnS0fayjFEHFjn127pJTQsKFv+QLkutpswK+/yrIh2q7E\n3dhm9dw3bxbRb98euPZaEXcjLxMnyj5jx5oljvfek2vVpk3J/84gNdUMNZYDYSXuhYXyMh0woFxC\nWt4zc6a8cZ54QopmGRnO9zt9Wgbqevhhz2nabFJ8dvbQGeI+e7YIXteu5raUFBHelSvNdXv3ini4\ne4BbtJDRJouKTAFv3drcHkhxP/984MorxRtr0gT4299EICpXNkVowwYRkxo1yn4+f5GUJLHarCwR\n97ZtzZAFYFYKWYv8hoeYnl7cCfC3uAMSmsnMBD77TO6loUMllFK/vnld166VcJIvJZrERPk2QjNp\nafJt9dwdxT0zU+41Z6UNb+neXQTACI9s2WIOhOeKtm2l9GAM9rZli1yLKlVEUPbvl9nOxo0zSzy7\ndwMvvSTP7bvvyn4DB8qLwdk8xkuWSL1XOcWLw0rcly2TUWMrVEjmzBnxoI2RAoGSFVYGRqXZjz9K\nOMUdW7ZIsdOZIDdtKg9HZqZ4JLVqmdv69hUP8rvvzHXeDJ8ZHy83bFaWKeBWz71uXYkHO4p7WTww\nK0ZF60MPiUBWrSoCb/XcK9p0W9YXnrPK3oYNpaRhjdEa4n7smMRvARH5QIj7TTcB1asDo0fL/ZKS\nIt/dupnhQ+PbV88dMMV97VpJv1Mnc59GjeT/NEqFu3aVLSQDyL1x2WXmdd28Wf4L68iejhhevRHC\n2bzZjNH36yd2jx8v3uO//iXj+6ekyBSS//63OG3jxsk9WFBQsvSdkyPPbDmFZIAwE/cvv5R7tW9f\nPyZaWFg8ZlhaFiyQB3XoULmBzj/fs7gDElt2h5GGM48qJsaMnTs+lLVqAT17Fo8hGnMRXnSR6/MZ\nsdHMTBErQ8ytWGPMOTlyrmrV3OfDW+64A3j0UeCBB8x13btLGOPoUQl/+NpSJlAY4r5qlXiFzl4+\nvXtLZfa5czKs8rp1wNVXyzbjWh4/LpXF/hb3mjXF0zxxQkpGTZvK+u7dRZzy8+XeiI/37SXdoIGU\npKyee+vWcl6DSpWkjsgalvHUUsYbeveWa5mfL6LqqjLVwNhueN3bt5uC37Ch1GstWSL/qdHSZ9Ik\neWG89JI4Gldead6DjqEZ40VjOHjlQNiIu80mrb/69ROB9xtjxpQtgD9zpoQmrrpKbuSuXT2Le+/e\nEgM1KgudsWKFiGurVs63G5WqzsS/f3+pbDUeKKPCzF1x0Vp8dmwpY2AV9+xs/4RkDOrUAV55RcJb\nBt27S8lo1izxbiua596kibzcvvxSll2J+6lT8gIwXrjjxsm3cS0dm0H6k+HD5XvYMHOdcc+sXOm5\nLsYdRMVbzDhWphoY9TlHjsinrJ47INeVWUrBO3a4j7cDUsqoXFnEPSNDnDrrC+HGG+X7rbfMmG+T\nJsBTT8nvceMkv61bSzqOlapLloizc/HFZc+bl4SNuP/+u+iJ30MyK1fKx9qiwVvy82UyipQUidMB\n8qBs2OB8CjtjQoJJk8R7MNpzM0tc1tqO3Gji6Co2acTdnT2YRohj4UIRR28qzIyXhTtxb91ahOjE\nCfHc/SnuzjBsNto0VzRxr1RJXr5Gu2dnJYsrr5T/cMkSEfeEBGkmGRNTUtwbN/a/jX37SpPJESPM\ndZ07y/06d67ck2WZ7cZo637ggOTDmbi3aCH3VVmbQVrp0kW8vPffF8/Pk+deubL8V1u2mBWr1hfC\n2LHSMOK664ofN368vEBSUmQ5JkbO5Uzce/Y0daAcCBtxnzNHQm2GbvkFZnnACgpKttf1hk8/lWMN\n7wiQB8Vmcz6t2/79Uoy95BLxFKZMERHv00eK6j16iFdx+LDcgO4eus6dxWtyJsKtWsn6BQtE2AsK\nPD/AVaqIuGzaJOEDV547IDaWh7g3aybe019/yYOckBDY8/mCcU3q1HHuederJ+GwhQulHW///iIA\nLVuacdtAeu5Ecm9ZRadGDXlRzpoly2UV9507zfvdleeem2uGMvwRlomJkefll19k2ZPnbuyzebPZ\nusbasql6dRFnR6KipGRvbaLaoUPxsMy2bfJM9OlT6myUhbAQ96IimTHthhuKl9rLTHZ28drz0lBY\nCLz5ptxg1qKY0XLFWWjGqDQjkmJebq4Ukf/6S9rW2mziaRmVoe4euvHj5aZy1S66f3/xJv77X89p\nGcTHiwAB7sU9Pb18xB0w7W7fvnRtwMsL45p07Oi6lNW7t7RWOXPG9E5aty6fsIwruneXl361amUr\nESUmmj0LgeKVqQaGp24IsT88d8CsvKxUyfn96kjbtvIi+vNPKan62vKqY0dpgXb4sCzPnCn//aBB\nvqXnIxXwaSg9S5dKqW/wYD8nbA2DWDs4eMM330gx04ifGtSpIzeRO3EHpMnUqFHAY4/JW//JJ8W7\ny8oC/v53uWEdOy854k7s+veXh+7NN72vMIuPN3tOOntYWraU77Vr5aVYnuJe0UIyBlZxd4UhQjVr\nmt5hUpL870VFcl/UqeO/ymlvMK5r585la7pntJj58kvJk2OfDMD01JcskWtQt67v57NiXNeEBCnW\ne6JdO3GgfvjBO0/fFcZ/vWGDlP5nzpTSUSDCam4IC3GfM0dess6GRSkThrg7dk32hsmT5cY2KmKs\ndO/uvDOTVdyJpGPEyy9LV3JAvP65c+UG7NCheKuD0tKjhzxohw97X+y2FpcNIbdSrZrE+pctk+Xy\nEHej8q+itZQxMPoCuLOvZ095EV97rVlZl5QknvPu3YFpBukJ47qWdXZ5Q9zz8pyHZIDilfXx8WVr\n427l0kulKO+tUBtx+ZMnPcfo3WH81+vXy3O+c2fJ8X3KATcNP0ODggJxCgYM8HMrGUDEvWpVEcLS\neO4rVsjn7bedV6B07w589JE0tzI8O5tNvHJPD3H//hIrL2tnncqVJcQzd673D7DxEDZt6vr8SUlm\nN+vyEPeuXYGpU2XIgopIly5Sd2JUuDmjVi3xUKwvAGuIKxjinpAgA3M5ViCWlmbNpLlgYWHJQb4M\nYmPl4T11yn8hGUDOO2eO9x5zUpK8ZG22snnujRtL6WPDBmk3X7Wq9HMpZ0Lec09NFafA7yEZwBz5\n8MIL5U+yDqbkjsmTxdu2tkCwYojpH3+Y63Jz5U3lzUPcr5/zyp3SYtxwV17p3f7Gg+cufml4nED5\niDsRMHJk8Y5aFYlKlYD77/dcyho0yHWPX29e+oFgxAjXYw15S3S0ed+48tyJzFKhPypTrfTr577/\nhpVq1Uxby+K5E0loJi1NXi433ug8HBVgQt5znzNHrptfOy4ZpKdLRV27duJV7Nnj/Obbtw+YNk3i\no4WFwFdfSYcbVw90UpLZptYgGJVmt90mlb3eVDYBZt49ibtBeYh7uBIbKy+szZulcrqc47V+JTFR\nSqnu2njHx0te/em5+0K7dtIyriziDkgp7O235XcQQjJAiIv7uXPScWngQO/qS0pFYaH8ybfcYv7R\nW7Y4F/cnnpDxOYzuzbGx0k3eFdY2tQZGG/fyfIiJvBd2QIrYyckSG3aFkV6lSnIdFN8w/ptff5US\nYzA8d3/Rt6+EJ426I2cYoh5scb/hBnHk6tQpWzpGpWrdugHyPD0T0mGZlSulQ1tAxpKxjnxo7Zrs\nyP79MpzvmDESjigoEE/L08NotKm1pgNU7Ic4OlraK998s+t9DHGPjS3XDhthSVKSeY9U5PvCE2PG\nFB/uwhmBCsuUlpEjpVNXWTHE/bbbig8WV46EtOdujE3lbrA3n7EOjlWvnoyT4azFzDvviGflzUiO\nVtq2lfDNmTNS7Ni/X7y1UA9lxMVJyaSssVqleKkqlMXdGwYNkvBmRRqyuSwYcw6MGRM0E0Lac8/L\nk29vJ6cpFY4jHzp62oC05Z46VTzZ0vaONNrUbt8uy8Z47xVq+igfiI6WikFjECrFdyJJ3OPiZLA8\ndyM3hhKVK8s4NAHxPL0jpK9kwMW9Th0z8bZtzQGqjHa4n3wicSHHjkreYA31dOgQnOZugWLWrPLt\ncBOuGOIeHa31F0qpCXlxr1kzQCGtbdvk4TKEvF07GVo2J0dCDkVF4ml07epbRw+jTa0R6tm/P/iV\nSf6ionYoCjUMcW/UqGIOraBUaEL6jsnLk0ljAkJ6evF2x46Vql99Ja1pxo/3rUed0abWSC+cPHfF\nP9SsKa2n9L5QfCCkPffc3ACFZE6eLDnyodFjbcsWqVy9915pA++u5YgnjHkbT5+WMVtCuS2zEhju\nvjtAN7kS7oS0uOflBei+N+Y4deyQU6uWjN08caJ0v1+4sGwVQG3bAosXmzO/q4emOPLcc8G2QAlR\nvArLEFFfItpGRBlENMHJ9keJaJ39s5GIiojIT0O7ucYncT982PnktVaczRFKJJ72d99JK5nvvzcn\nxPCVdu3EFmOWdhV3RVH8hEdxJ6IoAO8C6AegHYAUIio2qg4zT2LmTszcCcDjAJYyc34gDLZSanEv\nKJAB+F96yf1+hrg7jnx40UXSxOmbb/wzxKwRxzc6Tai4K4riJ7yJKXQBkMHMOwGAiGYDGAjA1TCJ\nKQA+9495rikslFaIpRL31atlRnljRncry5eb67/7zvnIhy+8IJ2VyjruhIGRjjEBhoq7oih+whtx\nbwJgr2V5H4CuznYkouoA+gIY7WL7fQDuA4DmZQxpGJOclErcjRnIHec3BIA77jAnjAaA228vuU/d\nuv6bSACQsaabNpXK2+rVK+7IhoqihBz+bgo5AMBvrkIyzDyNmZOZOTm2jJ0yjA5MpWoKmZoq31lZ\nZgJGYrt2yVR2J0/KZ8aMMtnnNUYrHGN6PUVRFD/gjbjvB9DMstzUvs4ZQ1AOIRlAmkECpfDcz56V\nsIsxdoV1Atu1a+W7a1fxoKtXLz+hNUIzGpJRFMWPeCPuqwG0IqJ4IoqBCPh8x52IqBaAKwF8618T\nnVPqoQdWrpRBuowBvqyhGUPcXc0UE0gMz13buCuK4kc8ijszF0Ji6D8A2AJgLjNvIqJRRDTKsuvN\nAH5k5pOBMbU4pRb3JUukC/dtt8k4HVZxT0uT3qL+jKd7i3ruiqIEAK964DDzIgCLHNZNdVieDmC6\nvwzzRKnFPTVVhuGsXVvGPrGGZdLSguO1A9LLtXr1ss3ZqCiK4kDIji2TlydNzj1NTQlAZlZZuRK4\n6ipZ7tgR2LhRBv86fFhmJ3c1v2OgqVNHzj98eHDOryhKWBKyww8YHZi8qvf8/XfpwNS7tyx37CiC\nv3On2fU/WOIOyDjuiqIofiSkxd3rZpCpqTLlW48esmwMSbt+vQg8ELywjKIoSgAIWXEv1YiQS5YA\nXbpIpyFA4tuVKkncfetWGSMmYGMHK4qilD8hHXP3StxPnZJhB3r1MtdVrw60aiWee1pacEMyiqIo\nASD8xX3TJqk4TU4uvr5DB4nFZ2SouCuKEnaEpLgzl0LcjfbsjqM4duwIHDggv1XcFUUJM0JS3I8f\nl1EhvRL3DRskDJOQUHy9Vey1MlVRlDAjJMW9VB2Y1q+XjkKOEwwbLWaaNpVp8xRFUcKIkBR3Y9Aw\njw1cmEXcnU2s0aKFtJ7RkIyiKGFISDaF9Npzz8mRnQ0v3UqlSsDMmSLyiqIoYUZ4i7urylSDAQP8\nZpOiKEpFIiTDMqUWd2eeu6IoShgTsuJOJGNuuWXDBhknvVRz8SmKooQ+ISvutWvLcDFucVWZqiiK\nEuaErLh7dMYLCoAtW1TcFUWJSEJS3HNzvWgGmZ4OnDun8XZFUSKSkBR3rzx3Ty1lFEVRwpjwFfcN\nG4DoaKBNm3KxSVEUpSIRvuK+fr0Ie0xMudikKIpSkQg5cT97Fjh50ktx15CMoigRSsiJu1cdmI4e\nBfbu1cpURVEilpATd68GDdu9W74TEwNuj6IoSkUk5MTdK889O1u+GzUKuD2KoigVkfAU96ws+W7c\nOOD2KIqiVERCTtwvuQR47z0gLs7NTuq5K4oS4YTckL8JCcCoUR52ysqSwWeqVSsXmxRFUSoaIee5\ne0V2tnrtiqJENOEr7hpvVxQlgglPcc/KUs9dUZSIJvzEnVnDMoqiRDzhJ+75+TLUr4ZlFEWJYMJP\n3LUZpKIoShiLu3ruiqJEMF6JOxH1JaJtRJRBRBNc7NOLiNYR0SYiWupfM0uB0TtVPXdFUSIYj52Y\niCgKwLsArgGwD8BqIprPzJst+9QGMAVAX2beQ0QNAmWwRzQsoyiK4pXn3gVABjPvZOZzAGYDGOiw\nz+0AvmLmPQDAzAf9a2YpyMoCzj8fqFEjaCYoiqIEG2/EvQmAvZblffZ1VpIA1CGiX4gojYjucJYQ\nEd1HRGuIaM2hQ4d8s9gT2gxSURTFbxWq0QAuBXADgOsA/IuIkhx3YuZpzJzMzMmxsbF+OrUD2jtV\nURTFK3HfD6CZZbmpfZ2VfQB+YOaTzJwLYBmAi/xjYinR3qmKoiheiftqAK2IKJ6IYgAMATDfYZ9v\nAfQgomgiqg6gK4At/jXVC7R3qqIoCgAvWsswcyERjQbwA4AoAB8x8yYiGmXfPpWZtxDRYgDrAdgA\nfMDMGwNpuFOOHAHOnNGwjKIoEY9X47kz8yIAixzWTXVYngRgkv9M8wFtBqkoigIg1HuonjsH/Oc/\n8g1o71RFURQ7oS3uixcD990HzJwpy9o7VVEUBUCoi/u2bfJtiLuGZRRFUQCEurinp8t3aiqwf794\n7jVrAuedF1y7FEVRgkzoi3vTptIEcvZsbQapKIpix6vWMhWW9HSgXz9g40YJzdSsqZWpiqIoCGXP\n/dgxICcHSEoChg4F/vwTWLtWPXdFURSEsrhv3y7fSUnAkCFAVBRw8qSKu6IoCkJZ3I3K1NatgYYN\ngT59ZFnDMoqiKCEu7kRAYqIsDxsm3+q5K4qihHCFano6EBcHVK0qy3/7G7BrF3DDDcG1S1EUpQIQ\n2uKeZBkyvkoV4F//Cp49iqIoFYjQDMswlxR3RVEU5X+EprgfPChNIVXcFUVRnBKa4m60lFFxVxRF\ncYqKu6IoShgSuuIeEwM0bx5sSxRFUSokoSvuLVtKr1RFURSlBKEp7tu2aUhGURTFDaEn7kVFQEaG\niruiKIobQk/cd+8GCgpU3BVFUdwQeuKuLWUURVE8Enrift55wMCBMhqkoiiK4pTQG1vm8svloyiK\norgk9Dx3RVEUxSMq7oqiKGGIiruiKEoYouKuKIoShqi4K4qihCEq7oqiKGGIiruiKEoYouKuKIoS\nhhAzB+fERIcA7Pbx8PoAcv1oTqgQifmOxDwDkZnvSMwzUPp8xzFzrKedgibuZYGI1jBzcrDtKG8i\nMd+RmGcgMvMdiXkGApdvDcsoiqKEISruiqIoYUioivu0YBsQJCIx35GYZyAy8x2JeQYClO+QjLkr\niqIo7glVz11RFEVxg4q7oihKGBJy4k5EfYloGxFlENGEYNsTCIioGREtIaLNRLSJiMbY19clov8S\n0Xb7d51g2+pviCiKiP4kogX25UjIc20imkdEW4loCxF1j5B8/8N+f28kos+JqGq45ZuIPiKig0S0\n0bLOZR6J6HG7tm0jouvKcu6QEnciigLwLoB+ANoBSCGidsG1KiAUAhjPzO0AdAPwoD2fEwD8zMyt\nAPxsXw43xgDYYlmOhDy/CWAxM7cBcBEk/2GdbyJqAuBhAMnM3B5AFIAhCL98TwfQ12Gd0zzan/Eh\nAC60HzPFrnk+EVLiDqALgAxm3snM5wDMBjAwyDb5HWbOZua19t/HIQ97E0heP7Hv9gmAm4JjYWAg\noqYAbgDwgWV1uOe5FoCeAD4EAGY+x8xHEOb5thMNoBoRRQOoDiALYZZvZl4GIN9htas8DgQwm5nP\nMvMuABkQzfOJUBP3JgD2Wpb32deFLUTUAsDFAP4A0JCZs+2bcgA0DJJZgeINAI8BsFnWhXue4wEc\nAvCxPRz1ARHVQJjnm5n3A3gVwB4A2QCOMvOPCPN823GVR7/qW6iJe0RBRDUBfAlgLDMfs25jacMa\nNu1Yiag/gIPMnOZqn3DLs51oAJcAeI+ZLwZwEg6hiHDMtz3OPBDycmsMoAYRDbPuE475diSQeQw1\ncd8PoJllual9XdhBRJUhwj6Tmb+yrz5ARI3s2xsBOBgs+wLA5QBuJKJMSLjtKiKagfDOMyDe2T5m\n/sO+PA8i9uGe7z4AdjHzIWYuAPAVgMsQ/vkGXOfRr/oWauK+GkArIoonohhI5cP8INvkd4iIIDHY\nLcw82bJpPoA77b/vBPBtedsWKJj5cWZuyswtIP9rKjMPQxjnGQCYOQfAXiJqbV91NYDNCPN8Q8Ix\n3Yiouv1+vxpStxTu+QZc53E+gCFEVIWI4gG0ArDK57Mwc0h9AFwPIB3ADgBPBtueAOWxB6Soth7A\nOvvnegD1ILXr2wH8BKBusG0NUP57AVhg/x32eQbQCcAa+//9DYA6EZLvZwFsBbARwGcAqoRbvgF8\nDqlTKICU0v7uLo8AnrRr2zYA/cpybh1+QFEUJQwJtbCMoiiK4gUq7oqiKGGIiruiKEoYouKuKIoS\nhqi4K4qihCEq7oqiKGGIiruiKEoY8v8SVPCK23+jFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe9dc4e9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYRhZhgm/YRhGlmHCbxiGkWX8P+f3JkXa2IZbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe9da77f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What observations do you make?\n",
    "\n",
    "Are you overfitting or underfitting? \n",
    "\n",
    "What can you do to improve it?\n",
    "\n",
    "Tip: Yes your assumption is true - although if you’re underfitting due to reasons other than dropout (or other regularization techniques), you won’t see this.\n",
    "\n",
    "The key technique to avoiding or circumventing underfitting is using a model with\n",
    "- plenty of layers and parameters\n",
    "- unfreeze and try to build yourself\n",
    "- Get more data (scrape the heck out of the web and get more data so your model can learn better)\n",
    "- picking an different architectures (e.g. CNN with batchnorm for images). Also picking appropriate learning rates.\n",
    "\n",
    "Interesting [explanation](https://www.youtube.com/watch?v=6kwQEBMandw&feature=youtu.be&t=4463) (not that I fully agree with all that he says)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas to Improve Algorithm Performance\n",
    "\n",
    "This list of ideas is not complete but it is a great start.\n",
    "\n",
    "\n",
    "I have divided the list into 4 sub-topics:\n",
    "\n",
    "### Improve Performance With Data.\n",
    "### Improve Performance With Algorithms.\n",
    "### Improve Performance With Algorithm Tuning.\n",
    "### Improve Performance With Ensembles.\n",
    "\n",
    "\n",
    "The gains often get smaller the further down the list. For example, a new framing of your problem or more data is often going to give you more payoff than tuning the parameters of your best performing algorithm. Not always, but in general.\n",
    "\n",
    "I have included lots of links to tutorials from the blog, questions from related sites as well as questions on the classic Neural Net FAQ.\n",
    "\n",
    "Some of the ideas are specific to artificial neural networks, but many are quite general. General enough that you could use them to spark ideas on improving your performance with other techniques.\n",
    "\n",
    "Let’s dive in.\n",
    "\n",
    "### 1. Improve Performance With Data\n",
    "\n",
    "You can get big wins with changes to your training data and problem definition. Perhaps even the biggest wins.\n",
    "\n",
    "Here’s a short list of what we’ll cover:\n",
    "\n",
    "Get More Data.\n",
    "Invent More Data.\n",
    "Rescale Your Data.\n",
    "Transform Your Data.\n",
    "Feature Selection.\n",
    "#### 1) Get More Data\n",
    "\n",
    "Can you get more training data?\n",
    "\n",
    "The quality of your models is generally constrained by the quality of your training data. You want the best data you can get for your problem.\n",
    "\n",
    "You also want lots of it.\n",
    "\n",
    "Deep learning and other modern nonlinear machine learning techniques get better with more data. Deep learning especially. It is one of the main points that make deep learning so exciting.\n",
    "\n",
    "Take a look at the following cartoon:\n",
    "\n",
    "Why Deep Learning?\n",
    "Why Deep Learning?\n",
    "Slide by Andrew Ng, all rights reserved.\n",
    "More data does not always help, but it can. If I am given the choice, I will get more data for the optionality it provides.\n",
    "\n",
    "Related:\n",
    "\n",
    "Datasets Over Algorithms\n",
    "#### 2) Invent More Data\n",
    "\n",
    "Deep learning algorithms often perform better with more data.\n",
    "\n",
    "We mentioned this in the last section.\n",
    "\n",
    "If you can’t reasonably get more data, you can invent more data.\n",
    "\n",
    "If your data are vectors of numbers, create randomly modified versions of existing vectors.\n",
    "If your data are images, create randomly modified versions of existing images.\n",
    "If your data are text, you get the idea…\n",
    "Often this is called data augmentation or data generation.\n",
    "\n",
    "You can use a generative model. You can also use simple tricks.\n",
    "\n",
    "For example, with photograph image data, you can get big gains by randomly shifting and rotating existing images. It improves the generalization of the model to such transforms in the data if they are to be expected in new data.\n",
    "\n",
    "This is also related to adding noise, what we used to call adding jitter. It can act like a regularization method to curb overfitting the training dataset.\n",
    "\n",
    "Related:\n",
    "\n",
    "Image Augmentation for Deep Learning With Keras\n",
    "What is jitter? (Training with noise)\n",
    "#### 3) Rescale Your Data\n",
    "\n",
    "This is a quick win.\n",
    "\n",
    "A traditional rule of thumb when working with neural networks is:\n",
    "\n",
    "Rescale your data to the bounds of your activation functions.\n",
    "\n",
    "If you are using sigmoid activation functions, rescale your data to values between 0-and-1. If you’re using the Hyperbolic Tangent (tanh), rescale to values between -1 and 1.\n",
    "\n",
    "This applies to inputs (x) and outputs (y). For example, if you have a sigmoid on the output layer to predict binary values, normalize your y values to be binary. If you are using softmax, you can still get benefit from normalizing your y values.\n",
    "\n",
    "This is still a good rule of thumb, but I would go further.\n",
    "\n",
    "I would suggest that you create a few different versions of your training dataset as follows:\n",
    "\n",
    "Normalized to 0 to 1.\n",
    "Rescaled to -1 to 1.\n",
    "Standardized.\n",
    "Then evaluate the performance of your model on each. Pick one, then double down.\n",
    "\n",
    "If you change your activation functions, repeat this little experiment.\n",
    "\n",
    "Big values accumulating in your network are not good. In addition, there are other methods for keeping numbers small in your network such as normalizing activation and weights, but we’ll look at these techniques later.\n",
    "\n",
    "Related:\n",
    "\n",
    "Should I standardize the input variables (column vectors)?\n",
    "How To Prepare Your Data For Machine Learning in Python with Scikit-Learn\n",
    "#### 4) Transform Your Data\n",
    "\n",
    "Related to rescaling suggested above, but more work.\n",
    "\n",
    "You must really get to know your data. Visualize it. Look for outliers.\n",
    "\n",
    "Guesstimate the univariate distribution of each column.\n",
    "\n",
    "Does a column look like a skewed Gaussian, consider adjusting the skew with a Box-Cox transform.\n",
    "Does a column look like an exponential distribution, consider a log transform.\n",
    "Does a column look like it has some features, but they are being clobbered by something obvious, try squaring, or square-rooting.\n",
    "Can you make a feature discrete or binned in some way to better emphasize some feature.\n",
    "Lean on your intuition. Try things.\n",
    "\n",
    "Can you pre-process data with a projection method like PCA?\n",
    "Can you aggregate multiple attributes into a single value?\n",
    "Can you expose some interesting aspect of the problem with a new boolean flag?\n",
    "Can you explore temporal or other structure in some other way?\n",
    "Neural nets perform feature learning. They can do this stuff.\n",
    "\n",
    "But they will also learn a problem much faster if you can better expose the structure of the problem to the network for learning.\n",
    "\n",
    "Spot-check lots of different transforms of your data or of specific attributes and see what works and what doesn’t.\n",
    "\n",
    "Related:\n",
    "\n",
    "How to Define Your Machine Learning Problem\n",
    "Discover Feature Engineering, How to Engineer Features and How to Get Good at It\n",
    "How To Prepare Your Data For Machine Learning in Python with Scikit-Learn\n",
    "#### 5) Feature Selection\n",
    "\n",
    "Neural nets are generally robust to unrelated data.\n",
    "\n",
    "They’ll use a near-zero weight and sideline the contribution of non-predictive attributes.\n",
    "\n",
    "Still, that’s data, weights, training cycles used on data not needed to make good predictions.\n",
    "\n",
    "Can you remove some attributes from your data?\n",
    "\n",
    "There are lots of feature selection methods and feature importance methods that can give you ideas of features to keep and features to boot.\n",
    "\n",
    "Try some. Try them all. The idea is to get ideas.\n",
    "\n",
    "Again, if you have time, I would suggest evaluating a few different selected “Views” of your problem with the same network and see how they perform.\n",
    "\n",
    "Maybe you can do as well or better with fewer features. Yay, faster!\n",
    "Maybe all the feature selection methods boot the same specific subset of features. Yay, consensus on useless features.\n",
    "Maybe a selected subset gives you some ideas on further feature engineering you can perform. Yay, more ideas.\n",
    "Related:\n",
    "\n",
    "An Introduction to Feature Selection\n",
    "Feature Selection For Machine Learning in Python\n",
    "#### 6) Reframe Your Problem\n",
    "\n",
    "Step back from your problem.\n",
    "\n",
    "Are the observations that you’ve collected the only way to frame your problem?\n",
    "\n",
    "Maybe there are other ways. Maybe other framings of the problem are able to better expose the structure of your problem to learning.\n",
    "\n",
    "I really like this exercise because it forces you to open your mind. It’s hard. Especially if you’re invested (ego!!!, time, money) in the current approach.\n",
    "\n",
    "Even if you just list off 3-to-5 alternate framings and discount them, at least you are building your confidence in the chosen approach.\n",
    "\n",
    "Maybe you can incorporate temporal elements in a window or in a method that permits timesteps.\n",
    "Maybe your classification problem can become a regression problem, or the reverse.\n",
    "Maybe your binary output can become a softmax output?\n",
    "Maybe you can model a sub-problem instead.\n",
    "It is a good idea to think through the problem and it’s possible framings before you pick up the tool, because you’re less invested in solutions.\n",
    "\n",
    "Nevertheless, if you’re stuck, this one simple exercise can deliver a spring of ideas.\n",
    "\n",
    "Also, you don’t have to throw away any of your prior work. See the ensembles section later on.\n",
    "\n",
    "Related:\n",
    "\n",
    "How to Define Your Machine Learning Problem\n",
    "### 2. Improve Performance With Algorithms\n",
    "\n",
    "Machine learning is about algorithms.\n",
    "\n",
    "All the theory and math describes different approaches to learn a decision process from data (if we constrain ourselves to predictive modeling).\n",
    "\n",
    "You’ve chosen deep learning for your problem. Is it really the best technique you could have chosen?\n",
    "\n",
    "In this section, we’ll touch on just a few ideas around algorithm selection before next diving into the specifics of getting the most from your chosen deep learning method.\n",
    "\n",
    "Here’s the short list\n",
    "\n",
    "Spot-Check Algorithms.\n",
    "Steal From Literature.\n",
    "Resampling Methods.\n",
    "Let’s get into it.\n",
    "\n",
    "#### 1) Spot-Check Algorithms\n",
    "\n",
    "Brace yourself.\n",
    "\n",
    "You cannot know which algorithm will perform best on your problem beforehand.\n",
    "\n",
    "If you knew, you probably would not need machine learning.\n",
    "\n",
    "What evidence have you collected that your chosen method was a good choice?\n",
    "\n",
    "Let’s flip this conundrum.\n",
    "\n",
    "No single algorithm can perform better than any other, when performance is averaged across all possible problems. All algorithms are equal. This is a summary of the finding from the no free lunch theorem.\n",
    "\n",
    "Maybe your chosen algorithms is not the best for your problem.\n",
    "\n",
    "Now, we are not trying to solve all possible problems, but the new hotness in algorithm land may not be the best choice on your specific dataset.\n",
    "\n",
    "My advice is to collect evidence. Entertain the idea that there are other good algorithms and given them a fair shot on your problem.\n",
    "\n",
    "Spot-check a suite of top methods and see which fair well and which do not.\n",
    "\n",
    "Evaluate some linear methods like logistic regression and linear discriminate analysis.\n",
    "Evaluate some tree methods like CART, Random Forest and Gradient Boosting.\n",
    "Evaluate some instance methods like SVM and kNN.\n",
    "Evaluate some other neural network methods like LVQ, MLP, CNN, LSTM, hybrids, etc.\n",
    "Double down on the top performers and improve their chance with some further tuning or data preparation.\n",
    "\n",
    "Rank the results against your chosen deep learning method, how do they compare?\n",
    "\n",
    "Maybe you can drop the deep learning model and use something a lot simpler, a lot faster to train, even something that is easy to understand.\n",
    "\n",
    "Related:\n",
    "\n",
    "A Data-Driven Approach to Machine Learning\n",
    "Why you should be Spot-Checking Algorithms on your Machine Learning Problems\n",
    "Spot-Check Classification Machine Learning Algorithms in Python with scikit-learn\n",
    "#### 2) Steal From Literature\n",
    "\n",
    "A great shortcut to picking a good method, is to steal ideas from literature.\n",
    "\n",
    "Who else has worked on a problem like yours and what methods did they use.\n",
    "\n",
    "Check papers, books, blog posts, Q&A sites, tutorials, everything Google throws at you.\n",
    "\n",
    "Write down all the ideas and work your way through them.\n",
    "\n",
    "This is not about replicating research, it is about new ideas that you have not thought of that may give you a lift in performance.\n",
    "\n",
    "Published research is highly optimized.\n",
    "\n",
    "There are a lot of smart people writing lots of interesting things. Mine this great library for the nuggets you need.\n",
    "\n",
    "Related:\n",
    "\n",
    "How to Research a Machine Learning Algorithm\n",
    "Google Scholar\n",
    "#### 3) Resampling Methods\n",
    "\n",
    "You must know how good your models are.\n",
    "\n",
    "Is your estimate of the performance of your models reliable?\n",
    "\n",
    "Deep learning methods are slow to train.\n",
    "\n",
    "This often means we cannot use gold standard methods to estimate the performance of the model such as k-fold cross validation.\n",
    "\n",
    "Maybe you are using a simple train/test split, this is very common. If so, you need to ensure that the split is representative of the problem. Univariate stats and visualization are a good start.\n",
    "Maybe you can exploit hardware to improve the estimates. For example, if you have a cluster or an Amazon Web Services account, we can train n-models in parallel then take the mean and standard deviation of the results to get a more robust estimate.\n",
    "Maybe you can use a validation hold out set to get an idea of the performance of the model as it trains (useful for early stopping, see later).\n",
    "Maybe you can hold back a completely blind validation set that you use only after you have performed model selection.\n",
    "Going the other way, maybe you can make the dataset smaller and use stronger resampling methods.\n",
    "\n",
    "Maybe you see a strong correlation with the performance of the model trained on a sample of the training dataset as to one trained on the whole dataset. Perhaps you can perform model selection and tuning using the smaller dataset, then scale the final technique up to the full dataset at the end.\n",
    "Maybe you can constrain the dataset anyway, take a sample and use that for all model development.\n",
    "You must have complete confidence in the performance estimates of your models.\n",
    "\n",
    "Related:\n",
    "\n",
    "Evaluate the Performance Of Deep Learning Models in Keras\n",
    "Evaluate the Performance of Machine Learning Algorithms in Python using Resampling\n",
    "### 3. Improve Performance With Algorithm Tuning\n",
    "\n",
    "This is where the meat is.\n",
    "\n",
    "You can often unearth one or two well-performing algorithms quickly from spot-checking. Getting the most from those algorithms can take, days, weeks or months.\n",
    "\n",
    "Here are some ideas on tuning your neural network algorithms in order to get more out of them.\n",
    "\n",
    "- Diagnostics.\n",
    "- Weight Initialization.\n",
    "- Learning Rate.\n",
    "- Activation Functions.\n",
    "- Network Topology.\n",
    "- Batches and Epochs.\n",
    "- Regularization.\n",
    "- Optimization and Loss.\n",
    "- \n",
    "Early Stopping.\n",
    "You may need to train a given “configuration” of your network many times (3-10 or more) to get a good estimate of the performance of the configuration. This probably applies to all the aspects that you can tune in this section.\n",
    "\n",
    "For a good post on hyperparameter optimization see:\n",
    "\n",
    "How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras\n",
    "#### 1) Diagnostics\n",
    "\n",
    "You will get better performance if you know why performance is no longer improving.\n",
    "\n",
    "Is your model overfitting or underfitting?\n",
    "\n",
    "Always keep this question in mind. Always.\n",
    "\n",
    "It will be doing one or the other, just by varying degrees.\n",
    "\n",
    "A quick way to get insight into the learning behavior of your model is to evaluate it on the training and a validation dataset each epoch, and plot the results.\n",
    "\n",
    "Plot of Model Accuracy on Train and Validation Datasets\n",
    "Plot of Model Accuracy on Train and Validation Datasets\n",
    "If training is much better than the validation set, you are probably overfitting and you can use techniques like regularization.\n",
    "If training and validation are both low, you are probably underfitting and you can probably increase the capacity of your network and train more or longer.\n",
    "If there is an inflection point when training goes above the validation, you might be able to use early stopping.\n",
    "Create these plots often and study them for insight into the different techniques you can use to improve performance.\n",
    "\n",
    "These plots might be the most valuable diagnostics you can create.\n",
    "\n",
    "Another useful diagnostic is to study the observations that the network gets right and wrong.\n",
    "\n",
    "On some problems, this can give you ideas of things to try.\n",
    "\n",
    "Perhaps you need more or augmented examples of the difficult-to-train on examples.\n",
    "Perhaps you can remove large samples of the training dataset that are easy to model.\n",
    "Perhaps you can use specialized models that focus on different clear regions of the input space.\n",
    "Related\n",
    "\n",
    "Display Deep Learning Model Training History in Keras\n",
    "Overfitting and Underfitting With Machine Learning Algorithms\n",
    "#### 2) Weight Initialization\n",
    "\n",
    "The rule of thumb used to be:\n",
    "\n",
    "Initialize using small random numbers.\n",
    "\n",
    "In practice, that is still probably good enough. But is it the best for your network?\n",
    "\n",
    "There are also heuristics for different activation functions, but I don’t remember seeing much difference in practice.\n",
    "\n",
    "Keep your network fixed and try each initialization scheme.\n",
    "\n",
    "Remember, the weights are the actual parameters of your model that you are trying to find. There are many sets of weights that give good performance, but you want better performance.\n",
    "\n",
    "Try all the different initialization methods offered and see if one is better with all else held constant.\n",
    "Try pre-learning with an unsupervised method like an autoencoder.\n",
    "Try taking an existing model and retraining a new input and output layer for your problem (transfer learning)\n",
    "Remember, changing the weight initialization method is closely tied with the activation function and even the optimization function.\n",
    "\n",
    "Related\n",
    "\n",
    "Initialization of deep networks\n",
    "#### 3) Learning Rate\n",
    "\n",
    "There is often payoff in tuning the learning rate.\n",
    "\n",
    "Here are some ideas of things to explore:\n",
    "\n",
    "Experiment with very large and very small learning rates.\n",
    "Grid search common learning rate values from the literature and see how far you can push the network.\n",
    "Try a learning rate that decreases over epochs.\n",
    "Try a learning rate that drops every fixed number of epochs by a percentage.\n",
    "Try adding a momentum term then grid search learning rate and momentum together.\n",
    "Larger networks need more training, and the reverse. If you add more neurons or more layers, increase your learning rate.\n",
    "\n",
    "Learning rate is coupled with the number of training epochs, batch size and optimization method.\n",
    "\n",
    "Related:\n",
    "\n",
    "Using Learning Rate Schedules for Deep Learning Models in Python with Keras\n",
    "What learning rate should be used for backprop?\n",
    "#### 4) Activation Functions\n",
    "\n",
    "You probably should be using rectifier activation functions.\n",
    "\n",
    "They just work better.\n",
    "\n",
    "Before that it was sigmoid and tanh, then a softmax, linear or sigmoid on the output layer. I don’t recommend trying more than that unless you know what you’re doing.\n",
    "\n",
    "Try all three though and rescale your data to meet the bounds of the functions.\n",
    "\n",
    "Obviously, you want to choose the right transfer function for the form of your output, but consider exploring different representations.\n",
    "\n",
    "For example, switch your sigmoid for binary classification to linear for a regression problem, then post-process your outputs. This may also require changing the loss function to something more appropriate. See the section on Data Transforms for more ideas along these lines.\n",
    "Related:\n",
    "\n",
    "Why use activation functions?\n",
    "#### 5) Network Topology\n",
    "\n",
    "Changes to your network structure will pay off.\n",
    "\n",
    "How many layers and how many neurons do you need?\n",
    "\n",
    "No one knows. No one. Don’t ask.\n",
    "\n",
    "You must discover a good configuration for your problem. Experiment.\n",
    "\n",
    "Try one hidden layer with a lot of neurons (wide).\n",
    "Try a deep network with few neurons per layer (deep).\n",
    "Try combinations of the above.\n",
    "Try architectures from recent papers on problems similar to yours.\n",
    "Try topology patterns (fan out then in) and rules of thumb from books and papers (see links below).\n",
    "It’s hard. Larger networks have a greater representational capability, and maybe you need it.\n",
    "\n",
    "More layers offer more opportunity for hierarchical re-composition of abstract features learned from the data. Maybe you need that.\n",
    "\n",
    "Later networks need more training, both in epochs and in learning rate. Adjust accordingly.\n",
    "Related:\n",
    "\n",
    "These links will give you lots of ideas of things to try, well they do for me.\n",
    "\n",
    "How many hidden layers should I use?\n",
    "How many hidden units should I use?\n",
    "#### 6) Batches and Epochs\n",
    "\n",
    "The batch size defines the gradient and how often to update weights. An epoch is the entire training data exposed to the network, batch-by-batch.\n",
    "\n",
    "Have you experimented with different batch sizes and number of epochs?\n",
    "\n",
    "Above, we have commented on the relationship between learning rate, network size and epochs.\n",
    "\n",
    "Small batch sizes with large epoch size and a large number of training epochs are common in modern deep learning implementations.\n",
    "\n",
    "This may or may not hold with your problem. Gather evidence and see.\n",
    "\n",
    "Try batch size equal to training data size, memory depending (batch learning).\n",
    "Try a batch size of one (online learning).\n",
    "Try a grid search of different mini-batch sizes (8, 16, 32, …).\n",
    "Try training for a few epochs and for a heck of a lot of epochs.\n",
    "Consider a near infinite number of epochs and setup check-pointing to capture the best performing model seen so far, see more on this further down.\n",
    "\n",
    "Some network architectures are more sensitive than others to batch size. I see Multilayer Perceptrons as often robust to batch size, whereas LSTM and CNNs quite sensitive, but that is just anecdotal.\n",
    "\n",
    "Related\n",
    "\n",
    "What are batch, incremental, on-line … learning?\n",
    "Intuitively, how does mini-batch size affect the performance of (stochastic) gradient descent?\n",
    "#### 7) Regularization\n",
    "\n",
    "Regularization is a great approach to curb overfitting the training data.\n",
    "\n",
    "The hot new regularization technique is dropout, have you tried it?\n",
    "\n",
    "Dropout randomly skips neurons during training, forcing others in the layer to pick up the slack. Simple and effective. Start with dropout.\n",
    "\n",
    "Grid search different dropout percentages.\n",
    "Experiment with dropout in the input, hidden and output layers.\n",
    "There are extensions on the dropout idea that you can also play with like drop connect.\n",
    "\n",
    "Also consider other more traditional neural network regularization techniques , such as:\n",
    "\n",
    "Weight decay to penalize large weights.\n",
    "Activation constraint, to penalize large activations.\n",
    "Experiment with the different aspects that can be penalized and with the different types of penalties that can be applied (L1, L2, both).\n",
    "\n",
    "Related:\n",
    "\n",
    "Dropout Regularization in Deep Learning Models With Keras\n",
    "What is Weight Decay?\n",
    "#### 8) Optimization and Loss\n",
    "\n",
    "It used to be stochastic gradient descent, but now there are a ton of optimizers.\n",
    "\n",
    "Have you experimented with different optimization procedures?\n",
    "\n",
    "Stochastic Gradient Descent is the default. Get the most out of it first, with different learning rates, momentum and learning rate schedules.\n",
    "\n",
    "Many of the more advanced optimization methods offer more parameters, more complexity and faster convergence. This is good and bad, depending on your problem.\n",
    "\n",
    "To get the most out of a given method, you really need to dive into the meaning of each parameter, then grid search different values for your problem. Hard. Time Consuming. It might payoff.\n",
    "\n",
    "I have found that newer/popular methods can converge a lot faster and give a quick idea of the capability of a given network topology, for example:\n",
    "\n",
    "ADAM\n",
    "RMSprop\n",
    "You can also explore other optimization algorithms such as the more traditional (Levenberg-Marquardt) and the less so (genetic algorithms). Other methods can offer good starting places for SGD and friends to refine.\n",
    "\n",
    "The loss function to be optimized might be tightly related to the problem you are trying to solve.\n",
    "\n",
    "Nevertheless, you often have some leeway (MSE and MAE for regression, etc.) and you might get a small bump by swapping out the loss function on your problem. This too may be related to the scale of your input data and activation functions that are being used.\n",
    "\n",
    "Related:\n",
    "\n",
    "An overview of gradient descent optimization algorithms\n",
    "What are conjugate gradients, Levenberg-Marquardt, etc.?\n",
    "On Optimization Methods for Deep Learning, 2011 [PDF]\n",
    "#### 9) Early Stopping\n",
    "\n",
    "You can stop learning once performance starts to degrade.\n",
    "\n",
    "This can save a lot of time, and may even allow you to use more elaborate resampling methods to evaluate the performance of your model.\n",
    "\n",
    "Early stopping is a type of regularization to curb overfitting of the training data and requires that you monitor the performance of the model on training and a held validation datasets, each epoch.\n",
    "\n",
    "Once performance on the validation dataset starts to degrade, training can stop.\n",
    "\n",
    "You can also setup checkpoints to save the model if this condition is met (measuring loss of accuracy), and allow the model to keep learning.\n",
    "\n",
    "Checkpointing allows you to do early stopping without the stopping, giving you a few models to choose from at the end of a run.\n",
    "\n",
    "Related:\n",
    "\n",
    "How to Check-Point Deep Learning Models in Keras\n",
    "What is early stopping?\n",
    "### 4. Improve Performance With Ensembles\n",
    "\n",
    "You can combine the predictions from multiple models.\n",
    "\n",
    "After algorithm tuning, this is the next big area for improvement.\n",
    "\n",
    "In fact, you can often get good performance from combining the predictions from multiple “good enough” models rather than from multiple highly tuned (and fragile) models.\n",
    "\n",
    "We’ll take a look at three general areas of ensembles you may want to consider:\n",
    "\n",
    "Combine Models.\n",
    "Combine Views.\n",
    "Stacking.\n",
    "#### 1) Combine Models\n",
    "\n",
    "Don’t select a model, combine them.\n",
    "\n",
    "If you have multiple different deep learning models, each that performs well on the problem, combine their predictions by taking the mean.\n",
    "\n",
    "The more different the models, the better. For example, you could use very different network topologies or different techniques.\n",
    "\n",
    "The ensemble prediction will be more robust if each model is skillful but in different ways.\n",
    "\n",
    "Alternately, you can experiment with the converse position.\n",
    "\n",
    "Each time you train the network, you initialize it with different weights and it converges to a different set of final weights. Repeat this process many times to create many networks, then combine the predictions of these networks.\n",
    "\n",
    "Their predictions will be highly correlated, but it might give you a small bump on those patterns that are harder to predict.\n",
    "\n",
    "Related:\n",
    "\n",
    "Ensemble Machine Learning Algorithms in Python with scikit-learn\n",
    "How to Improve Machine Learning Results\n",
    "#### 2) Combine Views\n",
    "\n",
    "As above, but train each network on a different view or framing of your problem.\n",
    "\n",
    "Again, the objective is to have models that are skillful, but in different ways (e.g. uncorrelated predictions).\n",
    "\n",
    "You can lean on the very different scaling and transform techniques listed above in the Data section for ideas.\n",
    "\n",
    "The more different the transforms and framing of the problem used to train the different models, the more likely your results will improve.\n",
    "\n",
    "Using a simple mean of predictions would be a good start.\n",
    "\n",
    "#### 3) Stacking\n",
    "\n",
    "You can also learn how to best combine the predictions from multiple models.\n",
    "\n",
    "This is called **stacked generalization** or stacking for short.\n",
    "\n",
    "Often you can get better results over that of a mean of the predictions using simple linear methods like regularized regression that learns how to weight the predictions from different models.\n",
    "\n",
    "Baseline reuslts using the mean of the predictions from the submodels, but lift performance with learned weightings of the models.\n",
    "\n",
    "Stacked Generalization (Stacking)\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "You made it.\n",
    "\n",
    "**Additional Resources**\n",
    "\n",
    "There’s a lot of good resources, but few tie all the ideas together.\n",
    "\n",
    "\n",
    "\n",
    "- Neural Network FAQ\n",
    "- How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras\n",
    "- Must Know Tips/Tricks in Deep Neural Networks\n",
    "- How to increase validation accuracy with deep neural net?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
